{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2244c06c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU langchain\n",
    "!pip install -qU openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b608453d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ColorfulSoles'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"What is a good name for a company that makes {product}?\"\n",
    ")\n",
    "runnable = prompt | ChatOpenAI(openai_api_key=\"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\", model_name=\"gpt-3.5-turbo\") | StrOutputParser()\n",
    "runnable.invoke({\"product\": \"colorful socks\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f09efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create chains\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=\"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\", \n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"tell me a joke about {foo}\")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcbe8ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the socks go to therapy?\\n\\nBecause they had too many colorful personalities!')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"foo\": \"colorful socks\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376bad9c",
   "metadata": {},
   "source": [
    "## chain our response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90682627-c3b4-48e7-bfda-145824816fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    {\"user_input\": \"Estoy bienes, gracias.\", \n",
    "     \"input_error\": \"the word, bienes, has a number disagreement error.\", \n",
    "     \"next_question\": \"¿Estás libre hoy?\"},\n",
    "    {\"user_input\": \"Sí, tengo algo de tiempos hoy.\", \n",
    "     \"input_error\": \"the word, tiempos, has a number disagreement error.\", \n",
    "     \"next_question\": \"¿Quieres ir de compras conmigo?\"},\n",
    "    {\"user_input\": \"Sí, necesito comprar un chaqueta.\", \n",
    "     \"input_error\": \"the word, un, has a gender disagreement error.\", \n",
    "     \"next_question\": \"¿A qué hora te gustaría ir?\"},\n",
    "    {\"user_input\": \"A las dieza.\", \n",
    "     \"input_error\": \"the word, dieza, has a gender disagreement error.\", \n",
    "     \"next_question\": \"Vale, nos vemos luego.\"},\n",
    "    {\"user_input\": \"Hasta luega.\", \n",
    "     \"input_error\": \"the word, luega, has a gender disagreement error.\", \n",
    "     \"next_question\": \"adiós!\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f54817-efc4-4a22-a25a-767e0bba1972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datas = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48923817-a504-4aba-a04e-53c12a3e96dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "869a3e6f-b321-42b0-9b9b-0a138a40f602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add input_error from GEC model\n",
    "prompt1 = PromptTemplate.from_template(\n",
    "    \"In '{user_input}', {input_error} Correct the phrase in Spanish with no explainations:\"\n",
    ")\n",
    "prompt2 = PromptTemplate.from_template(\n",
    "    \"Rephrase 'Veo, quieres decir {fixed_input}' in Spanish and nothing else:\"\n",
    ")\n",
    "prompt3 = PromptTemplate.from_template(\n",
    "    \"rephrase '{next_question}' in Spanish and nothing else:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3d7623a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = prompt1 | model\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"fixed_input\": chain1}\n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "#chain3 = (\n",
    "#    {\"scaffolding_input\": chain2}\n",
    "#    | prompt3\n",
    "#    | model\n",
    "#    | StrOutputParser()\n",
    "#)\n",
    "\n",
    "chain3 = prompt3 | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92ec3012-e37d-4093-a0f0-97c65794d400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veo, ¿quieres decir que en la frase 'la palabra bienes tiene un error de desacuerdo de número' hay un error de desacuerdo de número? 'Hoy estás libre?'\n",
      "\n",
      "En la palabra \"tiempos\", veo que hay un error de desacuerdo de número. ¿Te gustaría acompañarme de compras?\n",
      "\n",
      "En la frase \"Veo, quieres decir que en la palabra 'un' hay un error de desacuerdo de género\", la palabra 'un' tiene un error de desacuerdo de género. ¿A qué hora preferirías ir?\n",
      "\n",
      "Veo, quieres decir que la palabra \"dieza\" tiene un error de desacuerdo de género. Hasta luego, nos vemos.\n",
      "\n",
      "En la frase 'Veo, quieres decir que la palabra \"luega\" tiene un error de desacuerdo de género.' la palabra \"luega\" tiene un error de desacuerdo de género. Hasta luego.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, data in datas.iterrows():\n",
    "    gec_output = chain2.invoke({\"user_input\": data[\"input_error\"], \"input_error\": data[\"input_error\"]})\n",
    "    next_phrase = chain3.invoke({\"next_question\": data[\"next_question\"]})\n",
    "    print(gec_output + \" \" + next_phrase)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eff2ff-8cfc-46b7-afa6-7fb9144f2941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830cba3c-3efe-457e-aef2-2f3d46ecdce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567883b7-d54f-4d34-8c01-e641e31cecc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c6e4f-11ab-45b4-ab7c-2bfbe465f139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ca36993",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='My name is Mon.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"user_input\": \"I name is Mon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97540a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# detect the GEC and output the correct response\n",
    "prompt1 = PromptTemplate.from_template(\n",
    "    \"'{user_input}' has grammetical error. Return the correction and nothing else:\"\n",
    ")\n",
    "\n",
    "# add scaffolding with 'ahh, you mean...'\n",
    "prompt2 = PromptTemplate.from_template(\n",
    "    \"Return 'ahh, you mean {fixed_input}' and nothing else:\"\n",
    ")\n",
    "\n",
    "# continue the conversation with a question\n",
    "prompt3 = PromptTemplate.from_template(\n",
    "    \"keep it simple when rephrase {ask_question} and nothing else:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "636884a1-e599-498d-95fc-6aae11f502b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"En 'la palabra, luega, tiene un error de desacuerdo de género.', la palabra, luega, tiene un error de desacuerdo de género.\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.invoke({\"user_input\": data[\"input_error\"], \"input_error\": data[\"input_error\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03178423-b235-4785-9871-daef37564a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En la palabra \"luega\", veo que hay un error de discordancia de género.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\"user_input\": data[\"input_error\"], \"input_error\": data[\"input_error\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ade8e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_input = 'I name is Mon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e720386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ahh, you mean My name is Mon.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\"user_input\": \"I name is Mon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b804633b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'next_question'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m chain3 \u001b[38;5;241m=\u001b[39m prompt3 \u001b[38;5;241m|\u001b[39m model \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mchain3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mask_question\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwould you like to go shopping?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py:1427\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 1427\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1428\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1430\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/prompts/base.py:73\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Dict, config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     72\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_variables\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py:848\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    842\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    844\u001b[0m     run_type\u001b[38;5;241m=\u001b[39mrun_type,\n\u001b[1;32m    845\u001b[0m     name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 848\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    852\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/config.py:308\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    307\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/prompts/base.py:75\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Dict, config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     72\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\n\u001b[0;32m---> 75\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{key: inner_input[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables}\n\u001b[1;32m     76\u001b[0m         ),\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m     78\u001b[0m         config,\n\u001b[1;32m     79\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/prompts/base.py:75\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Dict, config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     72\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\n\u001b[0;32m---> 75\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{key: \u001b[43minner_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables}\n\u001b[1;32m     76\u001b[0m         ),\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m     78\u001b[0m         config,\n\u001b[1;32m     79\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m     )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'next_question'"
     ]
    }
   ],
   "source": [
    "chain3 = prompt3 | model | StrOutputParser()\n",
    "\n",
    "chain3.invoke({\"ask_question\": \"would you like to go shopping?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62188fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahh, you mean My name is Mon. Do you want to go shopping?\n"
     ]
    }
   ],
   "source": [
    "output = chain2.invoke({\"user_input\": \"I name is Mon\"}) + \" \" + chain3.invoke({\"ask_question\": \"would you like to go shopping?\"})\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
