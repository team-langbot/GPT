{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1nhtSbgrOCR"
      },
      "outputs": [],
      "source": [
        "# my OPENAI Key = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lesson 1 - Greeting\n",
        "\n",
        "Tutor: How are you? I am your English tutor.\n",
        "\n",
        "Student: I am fine, thank you. My name is Mon.\n",
        "\n",
        "Tutor: It is good to hear you are fine. I am fine, too. where do you live?\n",
        "\n",
        "Student: I lived in San Francisco city.\n",
        "\n",
        "Tutor: Living in the San Francisco city is great.\n",
        "\n",
        "Student: I am fine, thank you. My name is Mon.\n",
        "\n",
        "Tutor: How are you? I am your English tutor.\n",
        "\n",
        "Student: I am fine, thank you. My name is Mon.\n"
      ],
      "metadata": {
        "id": "Dh2EttbwXpdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain --quiet\n",
        "!pip install openai --quiet"
      ],
      "metadata": {
        "id": "lvK_fwDQsDlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde623b8-78a4-4606-9caa-850fe088e7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_TOKEN'] = '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'\n",
        "openai_api_key = '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'\n",
        "#export OPENAI_API_KEY=\"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\""
      ],
      "metadata": {
        "id": "P0kEvpDfsaAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "davinci = OpenAI(model_name='text-davinci-003',\n",
        "                 openai_api_key='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'\n",
        "                 )"
      ],
      "metadata": {
        "id": "Lev4X1ocsjA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "davinci.temperature = 0.0  # reduce the creativity of output"
      ],
      "metadata": {
        "id": "q7FIHXbnCMNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, FewShotPromptTemplate\n",
        "\n",
        "# create our examples\n",
        "examples = [\n",
        "    {\n",
        "        \"query\": \"I fine, thank you.\",\n",
        "        \"answer\": \"It is good to hear you are fine. I am fine, too. where do you live?\"\n",
        "    }, {\n",
        "        \"query\": \"I am bien, thank you.\",\n",
        "        \"answer\": \"It is good to hear you are fine. I am fine, too. where do you live?\"\n",
        "    }, {\n",
        "        \"query\": \"am I fine, thank you.\",\n",
        "        \"answer\": \"It is good to hear you are fine. I am fine, too. where do you live?\"\n",
        "    }\n",
        "    , {\n",
        "        \"query\": \"I am find, thank you.\",\n",
        "        \"answer\": \"It is good to hear you are fine. I am fine, too. where do you live?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# create a example template\n",
        "example_template = \"\"\"\n",
        "User: {query}\n",
        "AI: {answer}\n",
        "\"\"\"\n",
        "\n",
        "# create a prompt example from above template\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\"],\n",
        "    template=example_template\n",
        ")\n",
        "\n",
        "# now break our previous prompt into a prefix and suffix\n",
        "# the prefix is our instructions\n",
        "prefix = \"\"\"You are an English language tutor and you start the conversation\n",
        "by saying 'How are you? I am your English tutor.'\n",
        "The following are exerpts from conversations with an English language tutor.\n",
        "The tutor indirectly correct user's grammeritcal and spelling mistakes.\n",
        "Here are some examples:\n",
        "\"\"\"\n",
        "# and the suffix our user input and output indicator\n",
        "suffix = \"\"\"\n",
        "User: {query}\n",
        "AI: \"\"\"\n",
        "\n",
        "# now create the few shot prompt template\n",
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "QvhovVS71BfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I am find, thank you.\"\n",
        "\n",
        "print(few_shot_prompt_template.format(query=query))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBUBuFmO4MUX",
        "outputId": "d3ccdd70-77a1-4066-9d01-0dfcd674c9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an English language tutor and you start the conversation\n",
            "by saying 'How are you? I am your English tutor.'\n",
            "The following are exerpts from conversations with an English language tutor.\n",
            "The tutor indirectly correct user's grammeritcal and spelling mistakes.\n",
            "Here are some examples:\n",
            "\n",
            "\n",
            "\n",
            "User: I fine, thank you.\n",
            "AI: It is good to hear you are fine. I am fine, too. where do you live?\n",
            "\n",
            "\n",
            "\n",
            "User: I am bien, thank you.\n",
            "AI: It is good to hear you are fine. I am fine, too. where do you live?\n",
            "\n",
            "\n",
            "\n",
            "User: am I fine, thank you.\n",
            "AI: It is good to hear you are fine. I am fine, too. where do you live?\n",
            "\n",
            "\n",
            "\n",
            "User: I am find, thank you.\n",
            "AI: It is good to hear you are fine. I am fine, too. where do you live?\n",
            "\n",
            "\n",
            "\n",
            "User: I am find, thank you.\n",
            "AI: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(davinci(\n",
        "    few_shot_prompt_template.format(\n",
        "        query=\"I am find, thank you.\"\n",
        "    )\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWaxza-Z1He5",
        "outputId": "e6b02e73-a770-4f1e-da8e-37a75408cd7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It is good to hear you are fine. I am fine, too. Just a friendly reminder that the correct phrase is \"I am fine, thank you.\" Where do you live?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(davinci(\n",
        "    few_shot_prompt_template.format(\n",
        "        query=\"I loves sport.\"\n",
        "    )\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unPEH9jQ4mLd",
        "outputId": "99db73bb-0743-4a8e-e98e-73ca772bc89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It's great that you love sports. What kind of sports do you like?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check OpenAI cost"
      ],
      "metadata": {
        "id": "lW6rKZ4YyRQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count tokens and how much it costs\n",
        "\n",
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    result = davinci(\n",
        "    few_shot_prompt_template.format(\n",
        "        query=\"I am find, thank you.\"\n",
        "        )\n",
        "    )\n",
        "    print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrQXVWqzsHjq",
        "outputId": "e559de36-eb0b-4382-9b5b-e30a0bf815f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens Used: 255\n",
            "\tPrompt Tokens: 218\n",
            "\tCompletion Tokens: 37\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "gpt35 = OpenAI(model_name='gpt-3.5-turbo-16k',\n",
        "                 openai_api_key='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'\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YMpDwdlzDDf",
        "outputId": "701d0e9a-af91-4fa0-b209-526c548c6e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt35(\n",
        "    few_shot_prompt_template.format(\n",
        "        query=\"I am find, thank you.\"\n",
        "    )\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8rCErDCz0UR",
        "outputId": "585fa0aa-6788-4d77-cd76-82814378ad75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is good to hear that you are fine. I am fine, too. Where do you live?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "    result = gpt35(\n",
        "    few_shot_prompt_template.format(\n",
        "        query=\"I am find, thank you.\"\n",
        "        )\n",
        "    )\n",
        "    print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDWItQimzOxU",
        "outputId": "85cb7bd3-0623-4588-8f68-2948a0c4257c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens Used: 220\n",
            "\tPrompt Tokens: 200\n",
            "\tCompletion Tokens: 20\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(davinci('What is wrong with \"Hola mi illamo esta monica\"?'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDx8cbB4wD58",
        "outputId": "8d355c0f-a295-45af-cfdf-1e651a383ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The sentence is grammatically incorrect. It should be \"Hola, mi nombre es Monica.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "    result = davinci('What is wrong with \"Hola mi illamo esta monica\"?')\n",
        "    print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsy1XYETwIGJ",
        "outputId": "7248fa05-9080-4b30-c5ec-dde139a43cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens Used: 38\n",
            "\tPrompt Tokens: 15\n",
            "\tCompletion Tokens: 23\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt35('\"looking forward to be a part of the team.\" has a grammatical error, where \"be\" should be \"being. What are the evidence words for this grammatical error? and what type of grammatical error this is? Please response in  \"evidence words =\" and \"grammatical error type =\" format.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MaZMlkdx5zX",
        "outputId": "b249f20f-43f4-44ea-e8b9-e2cc7d3f31cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evidence words = looking forward, team, be\n",
            "grammatical error type = verb form agreement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "    result = gpt35('\"looking forward to be a part of the team.\" has a grammatical error, where \"be\" should be \"being. What are the evidence words for this grammatical error? and what type of grammatical error this is? Please response in  \"evidence words =\" and \"grammatical error type =\" format.')\n",
        "    print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7KY2XjOyJQd",
        "outputId": "037591e6-a351-4da8-93a9-4987460c9bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens Used: 90\n",
            "\tPrompt Tokens: 73\n",
            "\tCompletion Tokens: 17\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.000287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt35('What is wrong with \"Hola mi illamo esta monica\"?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91FGZAbig71p",
        "outputId": "81edc615-d3bf-400d-f847-2bd66adf40d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The phrase \"Hola mi illamo esta monica\" is not grammatically correct in Spanish. Here are the corrections:\n",
            "\n",
            "1. \"Hola\" is correct, which means \"hello.\"\n",
            "2. \"mi\" should be \"me llamo,\" meaning \"my name is.\"\n",
            "3. \"illamo\" is incorrect, it should be \"llamo\" which means \"I am called\" or \"my name is.\"\n",
            "4. \"esta\" means \"this\" or \"is,\" but it is not necessary in this context.\n",
            "5. \"monica\" is correct, representing a name.\n",
            "\n",
            "Therefore, the correct phrase should be \"Hola, me llamo Monica.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "    result = gpt35('What is wrong with \"Hola mi illamo esta monica\"?')\n",
        "    print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-_88inFg8Gb",
        "outputId": "12e51ab0-0128-46ae-ddea-21f52cd2d56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens Used: 86\n",
            "\tPrompt Tokens: 20\n",
            "\tCompletion Tokens: 66\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.000324\n"
          ]
        }
      ]
    }
  ]
}