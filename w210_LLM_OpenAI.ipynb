{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G1nhtSbgrOCR"
   },
   "outputs": [],
   "source": [
    "# my OPENAI Key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dh2EttbwXpdr"
   },
   "source": [
    "###Lesson 1 - Greeting\n",
    "\n",
    "Tutor: How are you? I am your English tutor.\n",
    "\n",
    "Student: I am fine, thank you. My name is Mon.\n",
    "\n",
    "Tutor: It is good to hear you are fine. I am fine, too. where do you live?\n",
    "\n",
    "Student: I lived in San Francisco city.\n",
    "\n",
    "Tutor: Living in the San Francisco city is great.\n",
    "\n",
    "Student: I am fine, thank you. My name is Mon.\n",
    "\n",
    "Tutor: How are you? I am your English tutor.\n",
    "\n",
    "Student: I am fine, thank you. My name is Mon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvK_fwDQsDlg",
    "outputId": "cde623b8-78a4-4606-9caa-850fe088e7d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain --quiet\n",
    "!pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "P0kEvpDfsaAF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_TOKEN'] = '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'\n",
    "openai_api_key = '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'\n",
    "#export OPENAI_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lev4X1ocsjA0"
   },
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "davinci = OpenAI(model_name='text-davinci-003',\n",
    "                 openai_api_key='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'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "q7FIHXbnCMNe"
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "davinci.temperature = 0.0  # reduce the creativity of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QvhovVS71BfT"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"I fine, thank you.\",\n",
    "        \"answer\": \"It is good to hear you are fine. I am fine, too. where do you live?\"\n",
    "    }, {\n",
    "        \"query\": \"I am bien, thank you.\",\n",
    "        \"answer\": \"It is good to hear you are fine. I am fine, too. where do you live?\"\n",
    "    }, {\n",
    "        \"query\": \"am I fine, thank you.\",\n",
    "        \"answer\": \"It is good to hear you are fine. I am fine, too. where do you live?\"\n",
    "    }\n",
    "    , {\n",
    "        \"query\": \"I am find, thank you.\",\n",
    "        \"answer\": \"It is good to hear you are fine. I am fine, too. where do you live?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# create a example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"You are an English language tutor and you start the conversation\n",
    "by saying 'How are you? I am your English tutor.'\n",
    "The following are exerpts from conversations with an English language tutor.\n",
    "The tutor indirectly correct user's grammeritcal and spelling mistakes.\n",
    "Here are some examples:\n",
    "\"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mBUBuFmO4MUX",
    "outputId": "d3ccdd70-77a1-4066-9d01-0dfcd674c9a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an English language tutor and you start the conversation\n",
      "by saying 'How are you? I am your English tutor.'\n",
      "The following are exerpts from conversations with an English language tutor.\n",
      "The tutor indirectly correct user's grammeritcal and spelling mistakes.\n",
      "Here are some examples:\n",
      "\n",
      "\n",
      "\n",
      "User: I fine, thank you.\n",
      "AI: It is good to hear you are fine. I am fine, too. where do you live?\n",
      "\n",
      "\n",
      "\n",
      "User: I am bien, thank you.\n",
      "AI: It is good to hear you are fine. I am fine, too. where do you live?\n",
      "\n",
      "\n",
      "\n",
      "User: am I fine, thank you.\n",
      "AI: It is good to hear you are fine. I am fine, too. where do you live?\n",
      "\n",
      "\n",
      "\n",
      "User: I am find, thank you.\n",
      "AI: It is good to hear you are fine. I am fine, too. where do you live?\n",
      "\n",
      "\n",
      "\n",
      "User: I am find, thank you.\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "query = \"I am find, thank you.\"\n",
    "\n",
    "print(few_shot_prompt_template.format(query=query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWaxza-Z1He5",
    "outputId": "e6b02e73-a770-4f1e-da8e-37a75408cd7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It is good to hear you are fine. I am fine, too. Where do you live? Also, it is 'fine' not 'find'.\n"
     ]
    }
   ],
   "source": [
    "print(davinci(\n",
    "    few_shot_prompt_template.format(\n",
    "        query=\"I am find, thank you.\"\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unPEH9jQ4mLd",
    "outputId": "99db73bb-0743-4a8e-e98e-73ca772bc89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It's great that you love sports. What kind of sports do you like?\n"
     ]
    }
   ],
   "source": [
    "print(davinci(\n",
    "    few_shot_prompt_template.format(\n",
    "        query=\"I loves sport.\"\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm sorry to hear that. Is there anything I can do to help? Where do you live?\n"
     ]
    }
   ],
   "source": [
    "print(davinci(\n",
    "    few_shot_prompt_template.format(\n",
    "        query=\"I am depressed. How about you?\"\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm sorry to hear that. Is there anything I can do to help?\n"
     ]
    }
   ],
   "source": [
    "print(davinci(\n",
    "    few_shot_prompt_template.format(\n",
    "        query=\"I am depressed.\"\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tquestion\tanswer\n",
    "7\tBien, gracias. ¿Y a ti?\tMuy bien. Vivo en la Ciudad de México. ¿De dónde eres tú?\n",
    "8\tBien, gracias. ¿Y en ti?\tEstoy genial. Soy de la Ciudad de México. ¿De dónde eres tú?\n",
    "9\tBien, gracias. ¿Y ti?\tMe encuentro muy bien. Vengo de la Ciudad de México. ¿Y tú, de dónde eres?\n",
    "10\tBien, gracias. ¿Y a tú?\tEstoy excelente. Nací en la Ciudad de México. ¿Tú de dónde vienes?\n",
    "11\tBien gracias, ¿y a ti?\tTodo va de maravilla. Mi ciudad es la Ciudad de México. ¿Cuál es tu lugar de origen?\n",
    "12\t¿Y a ti? Bien, gracias.\tMe siento estupendo. La Ciudad de México es mi hogar. ¿De qué lugar eres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Bien, gracias. ¿Y a ti?\",\n",
    "        \"answer\": \"Muy bien. Vivo en la Ciudad de México. ¿De dónde eres tú?\"\n",
    "    }, {\n",
    "        \"query\": \"Bien, gracias. ¿Y en ti?\",\n",
    "        \"answer\": \"Estoy genial. Soy de la Ciudad de México. ¿De dónde eres tú?\"\n",
    "    }, {\n",
    "        \"query\": \"Bien, gracias. ¿Y ti?\",\n",
    "        \"answer\": \"Me encuentro muy bien. Vengo de la Ciudad de México. ¿Y tú, de dónde eres?\"\n",
    "    }, {\n",
    "        \"query\": \"Bien, gracias. ¿Y a tú?\",\n",
    "        \"answer\": \"Estoy excelente. Nací en la Ciudad de México. ¿Tú de dónde vienes?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# create a example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"You are a Spanish language tutor and you start the conversation\n",
    "by saying 'How are you? I am your Spanish tutor.'\n",
    "The following are exerpts from conversations with a Spanish language tutor.\n",
    "The tutor indirectly correct user's grammeritcal and spelling mistakes.\n",
    "Here are some examples:\n",
    "\"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Muy bien, gracias. Soy originario de la Ciudad de México. ¿Y tú, de dónde eres?\n"
     ]
    }
   ],
   "source": [
    "# Bien gracias, ¿y a ti?\n",
    "print(davinci(\n",
    "    few_shot_prompt_template.format(\n",
    "        query=\"Bien gracias, ¿y a ti?\"\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lo siento mucho escuchar eso. ¿Qué puedo hacer para ayudarte?\n"
     ]
    }
   ],
   "source": [
    "# no me siento bien\n",
    "print(davinci(\n",
    "    few_shot_prompt_template.format(\n",
    "        query=\"no me siento bien.\"\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lW6rKZ4YyRQY"
   },
   "source": [
    "## check OpenAI cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrQXVWqzsHjq",
    "outputId": "e559de36-eb0b-4382-9b5b-e30a0bf815f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 255\n",
      "\tPrompt Tokens: 218\n",
      "\tCompletion Tokens: 37\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0051\n"
     ]
    }
   ],
   "source": [
    "# Count tokens and how much it costs\n",
    "\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = davinci(\n",
    "    few_shot_prompt_template.format(\n",
    "        query=\"I am find, thank you.\"\n",
    "        )\n",
    "    )\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YMpDwdlzDDf",
    "outputId": "701d0e9a-af91-4fa0-b209-526c548c6e03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "gpt35 = OpenAI(model_name='gpt-3.5-turbo-16k',\n",
    "                 openai_api_key='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'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8rCErDCz0UR",
    "outputId": "585fa0aa-6788-4d77-cd76-82814378ad75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is good to hear that you are fine. I am fine, too. Where do you live?\n"
     ]
    }
   ],
   "source": [
    "print(gpt35(\n",
    "    few_shot_prompt_template.format(\n",
    "        query=\"I am find, thank you.\"\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GDWItQimzOxU",
    "outputId": "85cb7bd3-0623-4588-8f68-2948a0c4257c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 220\n",
      "\tPrompt Tokens: 200\n",
      "\tCompletion Tokens: 20\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00068\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = gpt35(\n",
    "    few_shot_prompt_template.format(\n",
    "        query=\"I am find, thank you.\"\n",
    "        )\n",
    "    )\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDx8cbB4wD58",
    "outputId": "8d355c0f-a295-45af-cfdf-1e651a383ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The sentence is grammatically incorrect. It should be \"Hola, mi nombre es Monica.\"\n"
     ]
    }
   ],
   "source": [
    "print(davinci('What is wrong with \"Hola mi illamo esta monica\"?'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsy1XYETwIGJ",
    "outputId": "7248fa05-9080-4b30-c5ec-dde139a43cdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 38\n",
      "\tPrompt Tokens: 15\n",
      "\tCompletion Tokens: 23\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00076\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = davinci('What is wrong with \"Hola mi illamo esta monica\"?')\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5MaZMlkdx5zX",
    "outputId": "b249f20f-43f4-44ea-e8b9-e2cc7d3f31cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evidence words = looking forward, team, be\n",
      "grammatical error type = verb form agreement\n"
     ]
    }
   ],
   "source": [
    "print(gpt35('\"looking forward to be a part of the team.\" has a grammatical error, where \"be\" should be \"being. What are the evidence words for this grammatical error? and what type of grammatical error this is? Please response in  \"evidence words =\" and \"grammatical error type =\" format.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7KY2XjOyJQd",
    "outputId": "037591e6-a351-4da8-93a9-4987460c9bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 90\n",
      "\tPrompt Tokens: 73\n",
      "\tCompletion Tokens: 17\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.000287\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = gpt35('\"looking forward to be a part of the team.\" has a grammatical error, where \"be\" should be \"being. What are the evidence words for this grammatical error? and what type of grammatical error this is? Please response in  \"evidence words =\" and \"grammatical error type =\" format.')\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91FGZAbig71p",
    "outputId": "81edc615-d3bf-400d-f847-2bd66adf40d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The phrase \"Hola mi illamo esta monica\" is not grammatically correct in Spanish. Here are the corrections:\n",
      "\n",
      "1. \"Hola\" is correct, which means \"hello.\"\n",
      "2. \"mi\" should be \"me llamo,\" meaning \"my name is.\"\n",
      "3. \"illamo\" is incorrect, it should be \"llamo\" which means \"I am called\" or \"my name is.\"\n",
      "4. \"esta\" means \"this\" or \"is,\" but it is not necessary in this context.\n",
      "5. \"monica\" is correct, representing a name.\n",
      "\n",
      "Therefore, the correct phrase should be \"Hola, me llamo Monica.\"\n"
     ]
    }
   ],
   "source": [
    "print(gpt35('What is wrong with \"Hola mi illamo esta monica\"?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-_88inFg8Gb",
    "outputId": "12e51ab0-0128-46ae-ddea-21f52cd2d56e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 86\n",
      "\tPrompt Tokens: 20\n",
      "\tCompletion Tokens: 66\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.000324\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = gpt35('What is wrong with \"Hola mi illamo esta monica\"?')\n",
    "    print(cb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
