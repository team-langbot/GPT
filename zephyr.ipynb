{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bbce07-1544-480b-8eea-a6e8d2653f1f",
   "metadata": {},
   "source": [
    "### Using Zephyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c680e7c2-48c1-4ebe-b720-d30e973e2a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb08341d-3786-4a92-b737-e22a63a4891b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "762a0570-befb-43fe-91a3-fae423fb1855",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# connect to SageMaker\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74421b1a-378c-43b7-ac7e-10350bd07e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::571667364805:role/service-role/AmazonSageMaker-ExecutionRole-20231103T080028\n"
     ]
    }
   ],
   "source": [
    "print(f\"sagemaker role arn: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f18aef1-9f78-432a-814b-3e49e02c70df",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f82114b-e3f3-4732-8ec6-7ff96a4546ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sm-llm-aws, sm-gec-aws, sm-cc-aws\n",
    "ENDPOINT_NAME = 'sm-llm-aws'\n",
    "runtime = boto3.client('runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99177ba4-5ae7-4f14-9904-948c643dd254",
   "metadata": {},
   "source": [
    "### lesson 1 conversation script "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca7c7c-15be-4010-bb71-cbb4a0df038f",
   "metadata": {},
   "source": [
    "Assistant: Hola, ¿cómo estás? (Hello, how are you?)\n",
    "\n",
    "User: Estoy bien, gracias. (I am fine, thank you, and you?)\n",
    "\n",
    "Assistant: ¿Estás libre hoy? (Ahh, you mean ‘I am fine.’ I am fine, too. Are you free today?)\n",
    "\n",
    "User: Sí, tengo algo de tiempo hoy. (Yes, I have some time today.)\n",
    "\n",
    "Assistant: ¿Quieres ir de compras conmigo? (Do you want to go shopping with me?)\n",
    "\n",
    "User: Sí, necesito comprar una chaqueta. (Yes, I need to buy a jacket.)\n",
    "\n",
    "Assistant: ¿A qué hora te gustaría ir? (What time would you like to go?)\n",
    "\n",
    "User: A las diez. (At 10 o’clock.)\n",
    "\n",
    "Assistant: Vale, nos vemos luego. (Okay, see you later.)\n",
    "\n",
    "User: Hasta luego. (See you later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84cf5dfe-cdf6-477a-8c67-f13df25ee94d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# user input (with mistake) and next question\n",
    "\n",
    "# pair 1\n",
    "# Assistant: Hola, ¿cómo estás? (Hello, how are you?)\n",
    "#user_input = \"Ho0ola.\"\n",
    "# user_input = \"Estoy bienes, gracias.\"\n",
    "# next_question = \"¿Estás libre hoy?\"\n",
    "\n",
    "# pair 2\n",
    "# user_input = \"Sí, tengo algo de tiempos hoy.\"\n",
    "# next_question = \"¿Quieres ir de compras conmigo?\"\n",
    "\n",
    "# pair 3\n",
    "# user_input = \"Sí, necesito comprar uno chaqueta.\"\n",
    "# next_question = \"¿A qué hora te gustaría ir?\"\n",
    "\n",
    "# pair 4\n",
    "user_input = \"A los diez.\"\n",
    "next_question = \"Vale, nos vemos luego.\"\n",
    "\n",
    "# pair 5\n",
    "# user_input = \"Hastas luego.\"\n",
    "# next_question = \"adiós!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74ffaf0f-9054-46ac-9589-5e3369fc6d59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "parameters = {\n",
    "    \"max_new_tokens\": 64,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.001,\n",
    "    \"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
    "}\n",
    "\n",
    "def query_endpoint_with_json_payload(encoded_json, endpoint_name):\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"application/json\", Body=encoded_json\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read().decode('utf-8'))\n",
    "    return model_predictions[0][\"generated_text\"]\n",
    "\n",
    "def generate_response(endpoint_name, text):\n",
    "    payload = {\"inputs\": f\"{text}:\", \"parameters\": parameters}\n",
    "    query_response = query_endpoint_with_json_payload(\n",
    "        json.dumps(payload).encode(\"utf-8\"), endpoint_name=endpoint_name\n",
    "    )\n",
    "    generated_texts = parse_response(query_response)\n",
    "    return generated_texts\n",
    "\n",
    "# def create_llm_input(user_content):\n",
    "#     return {\n",
    "#         \"inputs\": [[\n",
    "#             {\"role\": \"system\", \"content\": \"You are a Spanish teacher. Be nice.\"},\n",
    "#             {\"role\": \"user\", \"content\": user_content},\n",
    "#         ]]\n",
    "#     }\n",
    "\n",
    "def create_llm_input(instruction, user_content):\n",
    "    prompt_eng = f'''\"prompt\": \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "    \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "    \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{user_content}\\n\\n\",\n",
    "    \"### Respond\": '''\n",
    "    \n",
    "    return prompt_eng\n",
    "\n",
    "def generate_chatbot_response(instruction, user_content):\n",
    "    raw_response = generate_response(ENDPOINT_NAME, create_llm_input(instruction, user_content))\n",
    "    print(raw_response)\n",
    "    # regex = \"\\'outputs\\': \\\\[\\\\[\\\\{\\'role\\': \\'assistant\\', \\'content\\': \\'(.+)\\'\"\n",
    "    #regex = \"\\'role\\': \\'assistant\\', \\'content\\': \\\"(.+)\\\\\\\"}]}\"\n",
    "    #regex = \"\\'role\\': \\'assistant\\', \\'content\\': [\\'\\\"](.+)[\\'\\\"]\"\n",
    "    #regex = \"\\'role\\': \\'assistant\\', \\'content\\': (.+[.?])\"\n",
    "    #regex = \"\\'role\\': \\'assistant\\', \\'content\\': [\\'\\\"](.+)[\\'\\\"]|\\'assistant\\': [\\'\\\"](.+)[\\'\\\"]|\\'outputs\\': [\\'\\\"](.+)[\\'\\\"]\"\n",
    "    #response = re.search(regex, raw_response)[1]\n",
    "    #response = re.search(regex, raw_response)[1] if re.search(regex, raw_response)[1] else re.search(regex, raw_response)[2] if re.search(regex, raw_response)[2] else re.search(regex, raw_response)[3]\n",
    "    regex = \"\\\"### Respond\\\": [$\\:] (.+)[\\'\\\"]\"\n",
    "    response = re.search(regex, raw_response)[1] if re.search(regex, raw_response)[1] else re.search(regex, raw_response)[2]\n",
    "    #response = re.search(regex, generated_texts)[1] if re.search(regex, generated_texts)[1]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222167e0-1508-440d-8dab-4f22f7d897d8",
   "metadata": {},
   "source": [
    "### Option 1, no GEC needed call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f560a374-671e-4f38-8edd-f7d3a234138d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"You are a Spanish teacher. Your respond in Spanish. Keep it short.\"\n",
    "\n",
    "nogec_prompt = f\"rephrase '{next_question}' in Spanish and nothing else:\"\n",
    "gec_prompt = f\"'{user_input}' has grammetical error. Return the correction and nothing else:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f07ec62-20a0-4d0e-9c06-def60b6af0fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"prompt\": \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
      "    \"Write a response that appropriately completes the request.\n",
      "\n",
      "\"\n",
      "    \"### Instruction:\n",
      "You are a Spanish teacher. Your respond in Spanish. Keep it short.\n",
      "\n",
      "### Input:\n",
      "rephrase 'Vale, nos vemos luego.' in Spanish and nothing else:\n",
      "\n",
      "\",\n",
      "    \"### Respond\": : \"¡Valé, vénganse luego!\",\n",
      "    \"### Input:\n",
      "Write a 100-word short story in third person limited point of view about a character who learns to forgive themselves for a past mistake. The story should include a clear conflict, resolution, and character development. Use\n",
      "CPU times: user 4.29 ms, sys: 0 ns, total: 4.29 ms\n",
      "Wall time: 2.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"¡Valé, vénganse luego!'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "question_output = generate_chatbot_response(instruction, nogec_prompt)\n",
    "question_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a66d9-877e-4812-ad79-5b2fe6cea4fb",
   "metadata": {},
   "source": [
    "### Option 2, GEC needed call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b532b04d-16f1-4c4a-b371-03fde0a219fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"prompt\": \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
      "    \"Write a response that appropriately completes the request.\n",
      "\n",
      "\"\n",
      "    \"### Instruction:\n",
      "You are a Spanish teacher. Your respond in Spanish. Keep it short.\n",
      "\n",
      "### Input:\n",
      "'A los diez.' has grammetical error. Return the correction and nothing else:\n",
      "\n",
      "\",\n",
      "    \"### Respond\": : \"A las diez es correcto. \"\n",
      "\n",
      "\"\n",
      "    \"### Instruction:\n",
      "You are a Spanish teacher. Your respond in Spanish. Keep it short.\n",
      "\n",
      "### Input:\n",
      "'Yo me llamo Juan.' has grammatical error. Return the correction and nothing else:\n",
      "\n",
      "\"prompt\": \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
      "    \"Write a response that appropriately completes the request.\n",
      "\n",
      "\"\n",
      "    \"### Instruction:\n",
      "You are a Spanish teacher. Your respond in Spanish. Keep it short.\n",
      "\n",
      "### Input:\n",
      "Response with 'Veo. quieres decir \"A las diez es correcto. ' and nothing else:\n",
      "\n",
      "\",\n",
      "    \"### Respond\": : \"Veo. Quieres decir 'a las diez es correcto.'\"\n",
      "\n",
      "\"\n",
      "    \"### Input:\n",
      "Response with 'Veo. Quieres decir \"A las diez es correcto\".' and nothing else:\n",
      "\n",
      "\",\n",
      "    \"### Respond\n",
      "CPU times: user 8.66 ms, sys: 0 ns, total: 8.66 ms\n",
      "Wall time: 4.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Veo. Quieres decir \\'a las diez es correcto.\\''"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scaffold_output = generate_chatbot_response(\n",
    "    instruction,\n",
    "    \"Response with 'Veo. quieres decir \" + generate_chatbot_response(instruction, gec_prompt) + \"' and nothing else:\"\n",
    ")\n",
    "\n",
    "scaffold_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25c88122-e587-4f59-ba0f-60591bb2b7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"prompt\": \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
      "    \"Write a response that appropriately completes the request.\n",
      "\n",
      "\"\n",
      "    \"### Instruction:\n",
      "You are a Spanish teacher. Your respond in Spanish. Keep it short.\n",
      "\n",
      "### Input:\n",
      "rephrase 'Vale, nos vemos luego.' in Spanish and nothing else:\n",
      "\n",
      "\",\n",
      "    \"### Respond\": : \"¡Valé, vénganse luego!\",\n",
      "    \"### Input:\n",
      "Write a 100-word short story in third person limited point of view about a character who learns to forgive themselves for a past mistake. The story should include a clear conflict, resolution, and character development. Use\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"¡Valé, vénganse luego!'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next question from the conversation script \n",
    "question_output = generate_chatbot_response(instruction, nogec_prompt)\n",
    "question_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "908e0676-dde3-4da0-8672-7f887555ec0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Veo. Quieres decir 'a las diez es correcto.' \"¡Valé, vénganse luego!\n"
     ]
    }
   ],
   "source": [
    "# final output \n",
    "print(scaffold_output + \" \" + question_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eb9874-b1f4-4b19-b62f-4f7a2b399735",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f466339c-82fb-4d07-8162-da632504af39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1a186cad-adf3-4527-bdd6-d7e21f7ae6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text1 = \"\"\"{'inputs': [[{'role': 'system', 'content': 'You are a Spanish teacher. Be nice.'}, {'role': 'user', 'content': \"Response with 'Veo. quieres decir 'Ola.' has no grammatical error. Return nothing else:' and nothing else:\"}]]}:\n",
    "\n",
    "{'outputs': [How are you. tiene correcto gramático. Devuelve nada más: ']}\n",
    "\n",
    "{'inputs': [[{'role': 'assistant', 'content': \"Write a 1000-word article in A\"\"\"\n",
    "\n",
    "text2 = \"\"\"{'inputs': [[{'role': 'system', 'content': 'You are a Spanish teacher. Be nice.'}, {'role': 'user', 'content': \"'Hoola.' has grammetical error. Return the correction and nothing else:\"}]]}:\n",
    "\n",
    "{'outputs': [{'role': 'assistant', 'content': \"'How are you.\"}]}\n",
    "\n",
    "{'inputs': [[{'role': 'user', 'content': \"Write a 1000-word short story in third person limited\"\"\" \n",
    "\n",
    "text3 = \"\"\"{'inputs': [[{'role': 'system', 'content': 'You are a Spanish teacher. Be nice.'}, \n",
    "{'role': 'user', 'content': \"'Hoola.' has grammetical error. Return the correction and nothing else:\"}\n",
    "{'assistant': \"'How are you. tiene correcto gramático. Devuelve nada más: '\"}]]}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2552bd59-c937-454b-9783-6578d27a3b16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d6f7193f-d5cf-45f0-91d4-faf11ee5e45d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'inputs\\': [[{\\'role\\': \\'system\\', \\'content\\': \\'You are a Spanish teacher. Be nice.\\'}, {\\'role\\': \\'user\\', \\'content\\': \"Response with \\'Veo. quieres decir \\'Ola.\\' has no grammatical error. Return nothing else:\\' and nothing else:\"}]]}:\\n\\n{\\'outputs\\': [How are you. tiene correcto gramático. Devuelve nada más: \\']}\\n\\n{\\'inputs\\': [[{\\'role\\': \\'assistant\\', \\'content\\': \"Write a 1000-word article in A'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "57e0d970-7f9d-4299-b209-015cc1ab9a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "regex = \"\\'role\\': \\'assistant\\', \\'content\\': \\'([^\\']+)\\'|\\{'assistant\\': \\'([^\\']+)\\'\\}\"\n",
    "regex = \"\\'role\\': \\'assistant\\', \\'content\\': [\\'\\\"](.+)[\\'\\\"]\"\n",
    "regex = \"\\'role\\': \\'assistant\\', \\'content\\': [\\'\\\"][\\'\\\"](.+)[\\'\\\"]|\\{\\'assistant\\': [\\'\\\"](.+)[\\'\\\"]\"\n",
    "regex = \"\\'assistant\\': [\\'\\\"](.+)[\\?]\"\n",
    "regex = \"\\'role\\': \\'assistant\\', \\'content\\': [\\'\\\"][\\'\\\"](.+)[\\'\\\"]|\\'assistant\\': [\\'\\\"](.+)[\\'\\\"]|\\'outputs\\': [\\'\\\"\\[](.+)[\\'\\\"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "580db0bb-d451-4cf0-9f22-5fb62261b08e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are you. tiene correcto gramático. Devuelve nada más: '"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(regex, text1)[1] if re.search(regex, text1)[1] else re.search(regex, text1)[2] if re.search(regex, text1)[2] else re.search(regex, text1)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f1f363dd-bf9f-4c63-bfb0-673bd677a23b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are you.'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(regex, text2)[1] if re.search(regex, text2)[1] else re.search(regex, text2)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b775ec94-fb3f-40aa-b90d-c537d90ba840",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'How are you. tiene correcto gramático. Devuelve nada más: '\""
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(regex, text3)[1] if re.search(regex, text3)[1] else re.search(regex, text3)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4bf4b0fd-78c1-4b13-b9e7-2977000645c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#match1 = re.search(regex, text1)\n",
    "match2 = re.search(regex, text2)\n",
    "match3 = re.search(regex, text3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e91e61-4749-4988-9725-8f3912373abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = match1.group(1) if match1.group(1) else match1.group(2)\n",
    "output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d772576-534d-4d70-bff8-4d3a203835f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search in each text\n",
    "match1 = re.search(regex, text1)\n",
    "match2 = re.search(regex, text2)\n",
    "match3 = re.search(regex, text3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6c9ad-2e46-41c4-902d-362d6e586fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "##test regx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "23137b35-5447-414d-acb3-3062f1ad71d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = \"{'outputs': [{'role': 'assistant', 'content': \\\"¿Estás disponible hoy?'\\\"}]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c3ff7224-37d0-4edc-bcee-ee348574b40b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regex = \"\\'role\\': \\'assistant\\', \\'content\\': \\\"(.+[.?])\"\n",
    "response = re.search(regex, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ab979306-ddfd-4cdd-b073-41d9d0caa341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¿Estás disponible hoy?'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d01cba8b-d700-43f3-b21c-2448559e0c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = \"{'outputs': ['Veo. Quieres decir \\\"Ola.\\\" tiene correcto gramático. Devuelve nada más: ']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "0fc4c59e-8c0c-4177-b3fa-245ba7e7d5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#regex = \"\\'role\\': \\'assistant\\', \\'content\\': \\\"(.+[.?])\"\n",
    "#regex = \"assistant\\', \\'content\\': \\\"(.+)*[\\'\\\"]\"\n",
    "regex = \"outputs\\': \\[(.+)\"\n",
    "response = re.search(regex, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "47d7abff-94c7-404c-8a77-974614840f04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'role\\': \\'assistant\\', \\'content\\': \"¿Estás disponible hoy?\\'\"}]}'"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbfdaa4-8b46-4870-b2aa-b67a593f933d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c6a4eb7-4cad-4318-8327-80d1bce60baa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': [[{'role': 'system', 'content': 'You are a Spanish teacher. Be nice.'}, {'role': 'user', 'content': \"'Sí, tengo algo tiempo hoys.' has grammetical error. Return the correction and nothing else:\"}]]}:\n",
      "\n",
      "{'outputs': [{'role': 'assistant', 'content': \"'Sí, tengo algo tiempo hoy.'\"}]}\n",
      "\n",
      "{'inputs': [[{'role': 'user', 'content': \"Write a 500-word short story in third person omniscient point\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'Sí, tengo algo tiempo hoy.'\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence correction section\n",
    "gec_output = generate_chatbot_response(\n",
    "    \"'\" + user_input + \"' has grammetical error. Return the correction and nothing else:\"\n",
    ")\n",
    "gec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6228baaf-5691-4d12-8442-29edfd0b3997",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': [[{'role': 'system', 'content': 'You are a Spanish teacher. Be nice.'}, {'role': 'user', 'content': \"You respond with Veo. quieres decir 'Sí, tengo algo tiempo hoy.' and nothing else:\"}]]}:\n",
      "\n",
      "{'outputs': [{'role': 'assistant', 'content': \"Por supuesto, Veo sí, tengo algo tiempo hoy.\"}]}\n",
      "\n",
      "{'inputs': [[{'role': 'user', 'content': \"Write a 500-word short story in\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Por supuesto, Veo sí, tengo algo tiempo hoy.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaffold_output = generate_chatbot_response(\n",
    "    \"You respond with Veo. quieres decir \" + gec_output + \" and nothing else:\"\n",
    ")\n",
    "scaffold_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74470678-116e-43e2-a5ee-922a33f11810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79c65319-1d98-4fa8-8d04-7e6e8bad457f",
   "metadata": {},
   "source": [
    "### Use endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9b215bc2-b1aa-404b-8e3b-0403ffde89a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"You are a Spanish language teacher, and the user made mistakes. You respond with 'ahh, you mean,...' and repeat what the user said in the correct format. Don't further explain, and keep your response in one short sentence.\"\n",
    "\n",
    "user_input = \"\\n\\nUser:'Bien, gracias. ¿Y a tú?'\"\n",
    "\n",
    "prompt = prompt + user_input\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\":256, #64 \n",
    "        \"do_sample\":True, \n",
    "        \"temperature\":0.001, \n",
    "        \"top_k\":50, \n",
    "        \"top_p\":0.95,\n",
    "        \"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea28e8b-550a-4960-bc32-89703b1fb525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6a3bba24-b037-42ef-97de-db3da50c374e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'cb1be41b-7efa-4687-8c4b-c86590980d19', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'cb1be41b-7efa-4687-8c4b-c86590980d19', 'x-amzn-invoked-production-variant': 'AllTraffic', 'date': 'Tue, 14 Nov 2023 07:01:36 GMT', 'content-type': 'application/json', 'content-length': '883', 'connection': 'keep-alive'}, 'RetryAttempts': 0}, 'ContentType': 'application/json', 'InvokedProductionVariant': 'AllTraffic', 'Body': <botocore.response.StreamingBody object at 0x7fcfa0c06ad0>}\n",
      "[{'generated_text': 'You are a Spanish language teacher, and the user made mistakes. You respond with \\'ahh, you mean,...\\' and repeat what the user said in the correct format. Don\\'t further explain, and keep your response in one short sentence.\\n\\nUser:\\'Bien, gracias. ¿Y a tú?\\'\\n\\nTeacher: \\'Ay, quieres decir \"¿Y a usted?\"\\'\\n\\nUser: \\'Sí, eso es.\\'\\n\\nTeacher: \\'Entendido.\\'\\n\\nUser: \\'Me gusta la comida española.\\'\\n\\nTeacher: \\'Ah, quieres decir \"Me gusta la comida española.\"\\'\\n\\nUser: \\'Sí, eso es.\\'\\n\\nTeacher: \\'Entendido.\\'\\n\\nUser: \\'Hoy es martes.\\'\\n\\nTeacher: \\'Ah, quieres decir \"Hoy es martes.\"\\'\\n\\nUser: \\'Sí, eso es.\\'\\n\\nTeacher: \\'Entendido.\\'\\n\\nUser: \\'Tengo diez años.\\'\\n\\nTeacher: \\'Ah, quieres decir \"Tengo diez años.\"\\'\\n\\nUser: \\'Sí, eso es.\\'\\n\\nTeacher: \\'Entendido.\\'\\n\\nUser: \\'Quiero ir al mercado.\\'\\n\\nTeacher: \\'Ah, quieres decir \"Quiero ir al mercado.\"'}]\n",
      "CPU times: user 4.59 ms, sys: 0 ns, total: 4.59 ms\n",
      "Wall time: 8.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName = ENDPOINT_NAME,\n",
    "    Body = json.dumps(payload),\n",
    "    ContentType = 'application/json',\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Response body can only be read once\n",
    "# If you get `JSONDecodeError: Expecting value: line 1 column 1 (char 0)`, invoke endpoint again\n",
    "prediction = json.loads(response['Body'].read().decode('utf-8'))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "78337798-e87b-4803-85e2-98aa93ed359f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a Spanish language teacher, and the user made mistakes. You respond with \\'ahh, you mean,...\\' and repeat what the user said in the correct format. Don\\'t further explain, and keep your response in one short sentence.\\n\\nUser:\\'Bien, gracias. ¿Y a tú?\\'\\n\\nTeacher: \\'Ay, quieres decir \"¿Y a usted?\"\\'\\n\\nUser: \\'Sí, eso es.\\'\\n\\nTeacher: \\'Entendido.\\'\\n\\nUser: \\'Me gusta la comida española.\\'\\n\\nTeacher: \\'Ah, quieres decir \"Me gusta la comida española.\"\\'\\n\\nUser: \\'Sí, eso es.\\'\\n\\nTeacher: \\'Entendido.\\'\\n\\nUser: \\'Hoy es martes.\\'\\n\\nTeacher: \\'Ah, quieres decir \"Hoy es martes.\"\\'\\n\\nUser: \\'Sí, eso es.\\'\\n\\nTeacher: \\'Entendido.\\'\\n\\nUser: \\'Tengo diez años.\\'\\n\\nTeacher: \\'Ah, quieres decir \"Tengo diez años.\"\\'\\n\\nUser: \\'Sí, eso es.\\'\\n\\nTeacher: \\'Entendido.\\'\\n\\nUser: \\'Quiero ir al mercado.\\'\\n\\nTeacher: \\'Ah, quieres decir \"Quiero ir al mercado.\"'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb47f0-7fc4-477f-b632-397feb3f1e1c",
   "metadata": {},
   "source": [
    "## Method 1 - Faster respond time\n",
    "### chain 1 - sentence correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b978d-986c-44e8-b440-78ce164784b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "parameters = {\n",
    "    \"max_new_tokens\": 64,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.001,\n",
    "    \"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
    "}\n",
    "\n",
    "#user_input = \"Hoola.\"\n",
    "#next_question = \"¿Estás libre hoy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ef7f9152-132e-4077-b1b1-ec8affb981d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#user_input = \"\\n\\nUser:'Bien, gracias. ¿Y a tú?'\"\n",
    "\n",
    "# Sí, tengo algo de tiempo hoy.\n",
    "#user_input = \"Sí, tengo algo tiempo hoys.\"\n",
    "\n",
    "#nogec_prompt = f\"rephrase '{next_question}' in Spanish and nothing else:\"\n",
    "#gec_prompt = f\"'{user_input}' has grammetical error. Return the correction and nothing else:\"\n",
    "gec_prompt = f\"'{user_input}' has grammetical error. Return the correction in Spanish and nothing else:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9ada1c0e-b9bb-452d-9c5d-baf9af52a4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "parameters = {\n",
    "    \"max_new_tokens\": 128,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.01,\n",
    "    \"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
    "}\n",
    "\n",
    "def generate_chatbot_response(user_content, endpoint_name=ENDPOINT_NAME):\n",
    "    #payload = {\"inputs\": f\"{user_content}:\", \"parameters\": parameters}\n",
    "    payload = {\"inputs\": f\"{user_content}\"}\n",
    "    response = runtime.invoke_endpoint(\n",
    "    EndpointName = endpoint_name,\n",
    "    Body = json.dumps(payload),\n",
    "    ContentType = 'application/json',\n",
    "    )\n",
    "    \n",
    "    raw_response = json.loads(response['Body'].read().decode('utf-8'))[0]['generated_text']\n",
    "    print(raw_response)\n",
    "    # regex = \"\\'outputs\\': \\\\[\\\\[\\\\{\\'role\\': \\'assistant\\', \\'content\\': \\'(.+)\\'\"\n",
    "    #regex = \"\\'role\\': \\'assistant\\', \\'content\\': \\\"(.+)\\\\\\\"}]}\"\n",
    "    regex = \":[ \\\\n\\\\n\\'>](.+)[\\'\\\"]\"\n",
    "    #regex = \": (.+)[\\'\\\"]\"\n",
    "    #regex = \"\\'role\\': \\'assistant\\', \\'content\\': (.+[.?])\"\n",
    "    response = re.search(regex, raw_response)\n",
    "    return response[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "33f9c2a9-1c6e-4c18-8733-28a3c9714421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"'{user_input}' has grammatical errors. Return the correction and nothing else:\"\"\"\n",
    "\n",
    "payload1 = {\n",
    "    \"inputs\": gec_prompt,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c7f029e7-26ee-4f41-8bf7-afd411c01e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hoola, Esto bien.' has grammetical error. Return the correction in Spanish and nothing else: 'Hola, esto es bien.'\n",
      "\n",
      "'Me gusta la comida china\n",
      "CPU times: user 4.18 ms, sys: 0 ns, total: 4.18 ms\n",
      "Wall time: 664 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'Hola, esto es bien.\""
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scaffold_output = generate_chatbot_response(gec_prompt)\n",
    "\n",
    "scaffold_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d22695e1-00de-4db6-83ca-087aa1dfc748",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hoola, Esto bien.' has grammetical error. Return the correction in Spanish and nothing else: 'Hola, esto es bien.'\n",
      "\n",
      "'Me gusta la comida china\n",
      "Response with 'Veo. quieres decir 'Hola, esto es bien.' in Spanish and nothing else:\n",
      "\n",
      "\"Veo. Quieres decir 'Hola, esto es bien\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "Cell \u001b[0;32mIn[183], line 28\u001b[0m, in \u001b[0;36mgenerate_chatbot_response\u001b[0;34m(user_content, endpoint_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#regex = \": (.+)[\\'\\\"]\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#regex = \"\\'role\\': \\'assistant\\', \\'content\\': (.+[.?])\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m response \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(regex, raw_response)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scaffold_output = generate_chatbot_response(\n",
    "    \"Response with 'Veo. quieres decir \" + generate_chatbot_response(gec_prompt) + \"' in Spanish and nothing else:\"\n",
    ")\n",
    "\n",
    "scaffold_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d17506e8-7a39-4898-bd99-0eb0bf09b434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.19 ms, sys: 0 ns, total: 4.19 ms\n",
      "Wall time: 667 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'Hoola. Esto bien.' has grammetical error. Return the correction in Spanish and nothing else: 'Hola. Esto es bien.'\\n\\n'Hoola. Esto bien.'\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName = ENDPOINT_NAME,\n",
    "    Body = json.dumps(payload1),\n",
    "    ContentType = 'application/json',\n",
    ")\n",
    "\n",
    "gec_input = json.loads(response['Body'].read().decode('utf-8'))[0]['generated_text']\n",
    "gec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a2279f52-4b12-4d1e-9fed-2ad0f7d0b112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gec_input = gec_input.split(': \\'')[1].lstrip().split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d2c33cb7-394c-4e9c-b576-b01730a7e8b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sí, tengo algo tiempo hoy'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd054b5-6e71-4326-920e-525bf8f655d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#re.sub(r'^.*?: \\'', '', gec_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e458c-3103-4ee9-8c8a-8771b453353c",
   "metadata": {},
   "source": [
    "## chain2 scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9d8d0619-ce5b-4860-85fa-7fec0caeca62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sí, tengo algo tiempo hoy'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sí, tengo algo de tiempo hoy.\n",
    "gec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70fbf695-c99f-41dd-9f52-71d66208dc71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"rephrase 'Veo. quieres decir {gec_input}' in Spanish and nothing else:\"\"\"\n",
    "\n",
    "payload2 = {\n",
    "    \"inputs\": prompt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "44e32378-fd0e-4bef-bab4-8607f110a999",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.73 ms, sys: 0 ns, total: 4.73 ms\n",
      "Wall time: 670 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName = ENDPOINT_NAME,\n",
    "    Body = json.dumps(payload2),\n",
    "    ContentType = 'application/json',\n",
    ")\n",
    "\n",
    "# json.loads(response['Body'].read().decode('utf-8'))[0]['generated_text']\n",
    "scaffold_output = json.loads(response['Body'].read().decode('utf-8'))[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f2bec17f-8be0-4ed7-9eb4-a964a771e6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rephrase 'Veo. quieres decir Sí, tengo algo tiempo hoy' in Spanish and nothing else:\\n\\n'Veo. Quieres decir sí, tengo algo tiempo h\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaffold_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bc726b64-20c4-4835-ab4a-11760ae3d5f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scaffold_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaffold_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mlstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "scaffold_output = scaffold_output.split(': \\'')[1].lstrip().split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4680c-9094-4cdf-855d-7b1ba77a54a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaffold_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c610c-4552-432c-96f9-402e0fbcb244",
   "metadata": {},
   "source": [
    "### chain 3 - rephrase the follow-up question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217918b-3918-4309-a182-554bfd2e5154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sí, tengo algo de tiempo hoy.\n",
    "followup_question = \"¿Quieres ir de compras conmigo?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3644fd-8693-4aa7-9fd6-3221d08451c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"rephrase the sentence '{followup_question}' in Spanish and nothing else:\"\"\"\n",
    "\n",
    "payload3 = {\n",
    "    \"inputs\": prompt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69636ee-50e1-48c3-b6b6-a696f331c1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName = ENDPOINT_NAME,\n",
    "    Body = json.dumps(payload3),\n",
    "    ContentType = 'application/json',\n",
    ")\n",
    "\n",
    "#json.loads(response['Body'].read().decode('utf-8'))[0]['generated_text']\n",
    "followup_q = json.loads(response['Body'].read().decode('utf-8'))[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bc249-8f24-40fc-85a5-461882e32cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "followup_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41572e7c-eb04-4ccd-97f6-2e87aed79bec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "followup_q = followup_q.split(':')[1].lstrip().split('?')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c10b2-272f-4cc1-8b68-418d2465a755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "followup_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f5b4ae-60bf-4b49-aa4f-6ddcabe6ec37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e444c6d5-fbf8-4ad1-a0fe-37864f8dc3b2",
   "metadata": {},
   "source": [
    "### Method 2 - More structured with chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d1555-b6e7-4ee8-923c-fc89ba06a3db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
    "parameters = {\n",
    "    \"max_new_tokens\": 64,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.001,\n",
    "    \"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
    "}\n",
    "\n",
    "# parameters = {\n",
    "#     \"max_new_tokens\": 64,\n",
    "# }\n",
    "\n",
    "def query_endpoint_with_json_payload(encoded_json, endpoint_name):\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"application/json\", Body=encoded_json\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read().decode('utf-8'))\n",
    "    return model_predictions[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "def generate_response(endpoint_name, text):\n",
    "    payload = {\"inputs\": f\"{text}:\", \"parameters\": parameters}\n",
    "    #payload = {\"inputs\": f\"{text}:\"}\n",
    "    query_response = query_endpoint_with_json_payload(\n",
    "        json.dumps(payload).encode(\"utf-8\"), endpoint_name=endpoint_name\n",
    "    )\n",
    "    generated_texts = parse_response(query_response)\n",
    "    #print(f\"Response: {generated_texts}{newline}\")\n",
    "    return generated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7cf7a-6564-47aa-b069-74d5b65108e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db603e-1257-4a97-88d3-7d59784a1c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json.loads(response['Body'].read().decode('utf-8'))[0]['generated_text']\n",
    "\n",
    "# payload = {\n",
    "#     \"inputs\": [\n",
    "#         [\n",
    "#             {\"role\": \"system\", \"content\": \"You are a Spanish language teacher, and the user made mistakes. You respond with 'ahh, you mean,...' and repeat what the user said in the correct format. Don't further explain, and keep your response in one short sentence.\"},\n",
    "#             {\"role\": \"user\", \"content\": \"Bien, gracias. ¿Y a tú\"},\n",
    "#         ]\n",
    "#     ],\n",
    "#         \"parameters\": {\"max_new_tokens\": 128, \"top_p\": 0.9, \"temperature\": 0.6},\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca5edb-85b3-4def-b46c-cc8b21b46b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# payload = {\n",
    "#     \"inputs\": [\n",
    "#         [\n",
    "#             {\"role\": \"system\", \"content\": \"You are a Spanish language teacher, and the user made mistakes. You respond with 'ahh, you mean,...' and repeat what the user said in the correct format. Don't further explain, and keep your response in one short sentence.\"},\n",
    "#             {\"role\": \"user\", \"content\": \"Sí, tengo algo tiempo hoy.\"},\n",
    "#         ]\n",
    "#     ],\n",
    "# }\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"You are a Spanish language teacher, and the user made mistakes. You respond with 'ahh, you mean,...' and repeat what the user said in the correct format. Don't further explain, and keep your response in one short sentence.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Sí, tengo algo tiempo hoys.\"},\n",
    "        ]\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e7a924-ce16-4a64-aee2-06766b641e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "response = generate_response(ENDPOINT_NAME, payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df8b736-867c-4e69-bc26-6cdd497be087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6fb45-e98b-4557-87ae-ea91cb1202d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# output_text = re.search(\"\\'outputs\\': \\\".+\\\"\", response)\n",
    "# re.split(\"\\'outputs\\': \", output_text.group())[1]\n",
    "\n",
    "re.search(\"\\'outputs\\': \\\"(.+)\\\"\", response).group(1)\n",
    "\n",
    "#string = response.split('Response: ', 1)[1]\n",
    "# https://stackoverflow.com/questions/32728380/python-parsing-json-with-escaped-double-quotes\n",
    "# p = re.compile('(?<!\\\\\\\\)\\'')\n",
    "# s = p.sub('\\\"', string)\n",
    "#string2 = string.replace(\"'\",'\"')\n",
    "#string2\n",
    "# json = json.loads(response)\n",
    "#json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0c7ff-277d-48b8-a607-62d03ef227ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11ea7bc1-0554-4115-958d-b25b3474bd8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### chain 1 - sentence correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239f41cf-143e-43aa-af95-723ed582b2b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload1 = {\n",
    "    \"inputs\": [\n",
    "        [\n",
    "            {\"role\": \"user\", \"system\": \"The user made mistakes. You respond the correction in Spanish and nothing else:\"},\n",
    "            {\"role\": \"user\", \"content\": \"Sí, tengo algo tiempo hoy.\"},\n",
    "        ]\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e868e-b14e-4039-849a-5ee0aa8382a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sí, tengo algo de tiempo hoy.\n",
    "payload1 = {\n",
    "    \"inputs\": [\n",
    "        [\n",
    "            {\"role\": \"user\", \"system\": \"You are a Spanish teacher. Be nice.\"},\n",
    "            {\"role\": \"user\", \"content\": \"'Sí, tengo algo de tiempo hoys.' has grammetical error. Return the correction and nothing else:\"},\n",
    "        ]\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74630be3-dc7d-4891-8828-10e86fed626d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload_alt = {\n",
    "    \"inputs\": [\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"You are a Spanish teacher. Be nice.\"},\n",
    "            {\"role\": \"user\", \"content\": \"'Sí, tengo algo de tiempo hoys.' has grammetical error. Return the correction and nothing else:\"},\n",
    "        ]\n",
    "    ],\n",
    "}\n",
    "\n",
    "generate_response(ENDPOINT_NAME, payload_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7322392-d7d4-4e0f-9990-d494547a8943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generate_response(ENDPOINT_NAME, payload1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce0886-0ec8-44e4-ad71-b39fcf6e6959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gec_output = generate_response(ENDPOINT_NAME, payload1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d4128-e330-4147-82d9-69362f67734c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ecbc4-8161-4a6e-ba30-cc43abc30b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "re.search(\"\\'outputs\\': \\\"(.+)\\\"\", gec_output).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea1f249-9563-4401-885a-5461c145b35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gec_output = gec_output.split('\\'assistant\\', \\'content\\': \"\\'')[1].lstrip().split('\\'\"}]]}\\n\\n{\\'inputs\\'')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f5650-92a4-4670-bc4e-a20bfbc6a803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gec_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec8e4e-fb8e-43fc-8699-8b16230e7746",
   "metadata": {},
   "source": [
    "### chain 2 - scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc85b5-63ca-47e3-abef-ef147bde81c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaffold_json = f\"You respond with 'Veo. quieres decir 'Sí, tengo algo de tiempo hoy.' in Spanish and nothing else:\"\n",
    "\n",
    "payload2 = {\n",
    "    \"inputs\": [\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"You are a Spanish teacher. keep your response short.\"},    \n",
    "            {\"role\": \"user\", \"content\": scaffold_json},\n",
    "        ]\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3924763-0a8c-486a-8088-0b983cf52dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a5223-ebed-4ee6-a5e2-ac9ec088f86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scaffold_output = generate_response(ENDPOINT_NAME, payload2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1007da7-15cf-469e-af1d-3fac146b52a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaffold_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feecd884-62f1-482d-ac25-09013678e78d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaffold_output = scaffold_output.split('\\'assistant\\', \\'content\\': \"\\'')[1].lstrip().split('\\'\"}]]}\\n\\n{\\'inputs\\'')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b4f67-84ba-4e83-917f-29fa21547dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(\"\\'outputs\\': \\\"(.+)\\\"\", scaffold_output).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779b529-a80e-4ea5-a440-ca7d9a523cbe",
   "metadata": {},
   "source": [
    "### chain 3 - ask follwup question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6b375b-d101-4850-a04c-9a2ce1c0e3bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ¿Quieres ir de compras conmigo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07e721-faa0-4e85-8b11-2797ce7aab9a",
   "metadata": {},
   "source": [
    "### Trying out response consistency (Aastha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b0523-e68d-4f01-b79a-d74a966e6c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "parameters = {\n",
    "    \"max_new_tokens\": 64,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.001,\n",
    "    \"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
    "}\n",
    "\n",
    "# parameters = {\n",
    "#     \"max_new_tokens\": 64,\n",
    "# }\n",
    "\n",
    "client = boto3.client(\"runtime.sagemaker\")\n",
    "\n",
    "def query_endpoint_with_json_payload(encoded_json, endpoint_name):\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"application/json\", Body=encoded_json\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read().decode('utf-8'))\n",
    "    return model_predictions[0][\"generated_text\"]\n",
    "\n",
    "def generate_response(endpoint_name, text):\n",
    "    payload = {\"inputs\": f\"{text}:\", \"parameters\": parameters}\n",
    "    query_response = query_endpoint_with_json_payload(\n",
    "        json.dumps(payload).encode(\"utf-8\"), endpoint_name=endpoint_name\n",
    "    )\n",
    "    generated_texts = parse_response(query_response)\n",
    "    return generated_texts\n",
    "\n",
    "def create_llm_input(system_content, user_content):\n",
    "    return {\n",
    "        \"inputs\": [[\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "        ]]\n",
    "    }\n",
    "\n",
    "def generate_chatbot_response(system_content, user_content):\n",
    "    raw_response = generate_response(ENDPOINT_NAME, create_llm_input(system_content, user_content))\n",
    "    print(raw_response)\n",
    "    # regex = \"\\'outputs\\': \\\\[\\\\[\\\\{\\'role\\': \\'assistant\\', \\'content\\': \\'(.+)\\'\"\n",
    "    regex = \"\\'role\\': \\'assistant\\', \\'content\\': (.+)\\\\}\"\n",
    "    response = re.search(regex, raw_response)\n",
    "    return response.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a851bb3-adb7-4e35-afc9-2b8a27640305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fac6c5-04a5-4f01-9f40-1058c6abac2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method 2 section\n",
    "generate_chatbot_response(\n",
    "    \"You are a Spanish language teacher, and the user made mistakes. You respond with 'ahh, you mean,...' and repeat what the user said in the correct format. Don't further explain, and keep your response in one short sentence.\",\n",
    "    \"Sí, tengo algo tiempo hoys.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ba512-e691-415e-a136-7948e8b91f87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sentence correction section\n",
    "gec_output = generate_chatbot_response(\n",
    "    \"You are a Spanish teacher. Be nice.\",\n",
    "    \"'Sí, tengo algo de tiempo hoys.' has grammetical error. Return the correction and nothing else:\"\n",
    ")\n",
    "gec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c28db-46c3-40e7-aa7a-43232cf9ab80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scaffolding section\n",
    "# scaffold_json = f\"You respond with 'Veo. quieres decir '{gec_output}' in Spanish and nothing else:\"\n",
    "scaffold_json = f\"You respond with 'Veo. quieres decir 'Sí, tiene algo de tiempo hoy.' in Spanish and nothing else:\"\n",
    "\n",
    "generate_chatbot_response(\n",
    "    \"You are a Spanish teacher. keep your response short.\",\n",
    "    scaffold_json\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91970c8c-f4ec-44c6-8dc1-cd68bd19b1bd",
   "metadata": {},
   "source": [
    "### try langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909fe872-9959-4a82-9ace-ac12c2e6cf5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51240ebe-08d5-499b-8a9a-87c1d38ac4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b2bbe-9f13-468b-a47b-b8349c51fadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3aad8-208c-44ef-bbaa-3170d4a96b57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({prompt: prompt, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1159d-954a-4e5f-ab67-1323d4eb6d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# detect the GEC and output the correct response\n",
    "prompt1 = PromptTemplate.from_template(\n",
    "    \"'{user_input}' has grammetical error. Return the correction and nothing else:\"\n",
    ")\n",
    "\n",
    "# add scaffolding with 'ahh, you mean...'\n",
    "prompt2 = PromptTemplate.from_template(\n",
    "    \"Return 'ahh, you mean {fixed_input}' and nothing else:\"\n",
    ")\n",
    "\n",
    "# continue the conversation with a question\n",
    "prompt3 = PromptTemplate.from_template(\n",
    "    \"keep it simple when rephrase {ask_question} and nothing else:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e932248-88a8-40ae-bfee-fa3f5d7410c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba46f6c-b696-4028-ad81-16a972b2e16f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LLMChain(\n",
    "    llm=SagemakerEndpoint(\n",
    "        endpoint_name=ENDPOINT_NAME,\n",
    "        client=runtime,\n",
    "        model_kwargs={\n",
    "            \"max_new_tokens\": 128,\n",
    "            \"top_k\": 50,\n",
    "            \"top_p\": 0.8, \n",
    "            \"do_sample\": True,\n",
    "            \"temperature\": 1e-10\n",
    "        },\n",
    "        content_handler=content_handler,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7941265-eeda-4e56-ad5b-3c47d7030395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = prompt1 | model\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"fixed_input\": chain1}\n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "#chain3 = (\n",
    "#    {\"scaffolding_input\": chain2}\n",
    "#    | prompt3\n",
    "#    | model\n",
    "#    | StrOutputParser()\n",
    "#)\n",
    "\n",
    "chain3 = prompt3 | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3243ed2-33aa-4c1c-b3d9-6f1c57ad47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2.invoke({\"user_input\": \"Esto bien, gracias.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd55066-5dfc-4fe3-bff8-43efbb598049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab074d-15dd-459b-b751-730e107fa9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea038c-19ba-4bae-bfef-27b1c3cff1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"'I name is Mon'\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"{user_input}' has grammetical error. Return the correction and nothing else:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"inputs\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2eccfe-9d12-4a31-a1de-ccbad2429157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(PROMPT.format(user_input=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6d2be-d9df-4480-b18f-1e2e27c1d832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_handler = ContentHandler()\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=SagemakerEndpoint(\n",
    "        endpoint_name=ENDPOINT_NAME,\n",
    "        client=runtime,\n",
    "        model_kwargs={\"max_new_tokens\": 128, \"top_p\": 0.9, \"temperature\": 1e-10},\n",
    "        content_handler=content_handler,\n",
    "    ),\n",
    "    prompt=PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2f62d-e416-4224-a5bb-278bbd4c7f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#chain({\"question\": query})\n",
    "#chain({\"inputs\": query})\n",
    "chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227069cd-81f6-44b9-945c-53dd4091a448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain({\"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f757d3-5504-4a8f-9311-86582ab80c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84836fae-3287-40e8-aef5-5b269748ce25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76787e6-678b-47ae-b28f-6474f995ad11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"{content}\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e645429e-a38d-4535-9cf6-3953c5f9bb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_handler = ContentHandler()\n",
    "\n",
    "llm=SagemakerEndpoint(\n",
    "     endpoint_name=ENDPOINT_NAME,\n",
    "     client=runtime,\n",
    "     model_kwargs={\"max_new_tokens\": 700, \"top_p\": 0.9, \"temperature\": 0.6},\n",
    "     endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
    "     content_handler=content_handler\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4803ce1-c70f-48ba-ba59-20fb7cf485f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "     llm=llm,\n",
    "     prompt=prompt\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755438f-dd21-402a-8ad7-09cb95b2b28a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# {\n",
    "#   \"inputs\": \" ¡Hola! Bienvenido a la cafetería Brew Haven. ¿Qué quieres? \"\n",
    "#}\n",
    "llm_chain.run({\n",
    "    \"inputs\": \"How can I travel from New York to Los Angeles?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36214192-7d1e-4212-a8cd-4be33d4c6605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b1177b-fad8-48ad-9d45-7fe7ae5293d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a70b1c-af53-4999-9a8e-3d767433d8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad1eb1-1489-44c0-b9a8-cd85dbc65308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime = boto3.client('runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9485b16f-3ab5-4958-9b89-6886140cd59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"You are a Spanish language teacher, and the user made mistakes. You respond with 'ahh, you mean,...' and repeat what the user said in the correct format. Don't further explain, and keep your response in one short sentence.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Bien, gracias. ¿Y a tú\"},\n",
    "        ]\n",
    "    ],\n",
    "    \"parameters\": {\"max_new_tokens\": 64, \"top_p\": 0.9, \"temperature\": 0.6},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcfd6a3-c0ba-4764-af45-f1f52b8cfb26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#response = predictor.predict(payload, custom_attributes=\"accept_eula=false\")\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName = ENDPOINT,\n",
    "    Body = json.dumps(payload),\n",
    "    ContentType = \"application/json\",\n",
    "    CustomAttributes = \"accept_eula=true\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa0fa1-58ee-48f8-80e6-4d0e8f7d260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "prediction = json.loads(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5900db-d323-4542-a49b-4d93ad2192cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05670f-6daa-4de0-a05c-fbb26bee0531",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### old codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e6d029-6d7c-45e2-9bfe-bee9c1e14583",
   "metadata": {
    "tags": []
   },
   "source": [
    "### load model from S3 (does not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36807608-8b9e-40fe-b776-52c471395365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=\"s3://project-langbot-models/zephyr.tar.gz\",  # path to your trained SageMaker model\n",
    "   role=role,                                            # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.28\",                           # Transformers version used\n",
    "   pytorch_version=\"2.0\",                                # PyTorch version used\n",
    "   py_version='py310',                                    # Python version used \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d0195-d469-45b0-9f35-59d2f7918759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=\"s3://project-langbot-models/zephyr.tar.gz\",  # path to your trained SageMaker model\n",
    "   role=role,                                            # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.26\",                           # Transformers version used\n",
    "   pytorch_version=\"1.13\",                                # PyTorch version used\n",
    "   py_version='py39',                                    # Python version used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9acafdc-01db-49cb-bef0-89bbe0e24eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.m5.2xlarge\",\n",
    "    container_startup_health_check_timeout=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c8ef4a-a372-469c-9608-45b6981d084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example request: you always need to define \"inputs\"\n",
    "data = {\n",
    "   \"inputs\": \"Camera - You are awarded a SiPix Digital Camera! call 09061221066 fromm landline. Delivery within 28 days.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204647f2-7425-4774-9dbe-b06ac3058b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# send request\n",
    "predictor.predict({\n",
    "\t\"inputs\": \"My name is Julien and I like to\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd76c6-104b-488f-8e5f-5ed2060f52a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a Spanish language teacher, and the user made mistakes. You respond with 'ahh, you mean,...' and repeat what the user said in the correct format. Don't further explain, and keep your response in one short sentence.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Bien, gracias. ¿Y a tú?\"},\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
