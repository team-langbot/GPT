{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "564dbfbe",
   "metadata": {},
   "source": [
    "## falcon 7B instruct talk in Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a92af65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2154f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.13s/it]\n"
     ]
    }
   ],
   "source": [
    "#model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "model = \"falcon_7b_instruct\"\n",
    "\n",
    "access_token = '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'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    token=access_token,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca3274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Mini:Hello, how are you?\n",
      "User: I'm doing well. How about you?\n",
      "Mini: I'm doing great, thank you! I'm glad to hear that you're doing well as well.\n",
      "User \n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "   \"Mini:Hello, how are you?\\nUser:\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "880fa2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: User:no me siento bien.\n",
      "Mini:no me siento mal (no me\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "   \"User:no me siento bien.\\nMini:\",\n",
    "    #max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a66a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shots\n",
    "input_text = \"\"\"\n",
    "Oració: Estoy bien, gracias.\n",
    "Paráfrasis: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
    "----\n",
    "Oració: no me sirve.\n",
    "Paráfrasis: Tú no estás bien, yo estoy bien. ¿Dónde vive?\n",
    "----\n",
    "Oración: Estoy bien.\n",
    "Paráfrasis: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
    "----\n",
    "Oració: Estoy muy bien.\n",
    "Paráfrasis:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c80fb2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shots\n",
    "input_text = \"\"\"\n",
    "User: Estoy bien, gracias.\n",
    "Mini: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
    "----\n",
    "User: no me sirve.\n",
    "Mini: Tú no estás bien, yo estoy bien. ¿Dónde vive?\n",
    "----\n",
    "User: Estoy muy bien.\n",
    "Mini:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d2efa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "User: Estoy bien, gracias.\n",
      "Mini: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
      "----\n",
      "User: no me sirve.\n",
      "Mini: Tú no estás bien, yo estoy bien. ¿Dónde vive?\n",
      "----\n",
      "User: Estoy muy bien.\n",
      "Mini: Tú no estás bien, yo tengo mala espina. ¿Dónde vivo?\n",
      "User: Estoy perfecto, no tengo dolencia. ¿Dónde vivo?\n",
      "Mini: Yo tengo una dolencia, tú no tengo\n",
      "CPU times: user 1.33 s, sys: 698 µs, total: 1.33 s\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequences = pipeline(\n",
    "    input_text,\n",
    "    max_length=128,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73132317",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "<human>: Estoy bien, gracias.\n",
    "<assistant>: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
    "----\n",
    "<human>: no me sirve.\n",
    "<assistant>: Tú no estás bien, yo estoy bien. ¿Dónde vive?\n",
    "----\n",
    "<human>: Estoy muy bien.\n",
    "<assistant>:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d9ba5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: <human>: Estoy bien, gracias.\n",
      "<assistant>: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
      "----\n",
      "<human>: no me sirve.\n",
      "<assistant>: Tú no estás bien, yo estoy bien. ¿Dónde vive?\n",
      "----\n",
      "<human>: Estoy muy bien.\n",
      "<assistant>: Tú no estás bien, yo estoy bien. ¿Dónde vivo?\n",
      "----\n",
      "<human>: Estoy bien.\n",
      "<assistant>: Tú no estás bien, yo estoy bien. ¿Dónde vivo?\n",
      "----\n",
      "<human>: Estoy bien.\n",
      "<ass\n",
      "CPU times: user 1.63 s, sys: 27.3 ms, total: 1.65 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sequences = pipeline(\n",
    "    input_text,\n",
    "    #max_length=128,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.7,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(f\"Result: {sequences[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535982f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.save_pretrained(\"falcon_7b_instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af46b51",
   "metadata": {},
   "source": [
    "## Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5924de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Bien, gracias. ¿Y en ti?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9404be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Eres profesor de lengua española, corriges errores diciéndolo correctamente indirectamente. mantenga su respuesta breve y simple.\n",
      "\n",
      "User: Bien, gracias. ¿Y en ti?\n",
      "Mini: Bien, gracias. ¿Y en ti?\n",
      "User \n"
     ]
    }
   ],
   "source": [
    "# prompt enginnering\n",
    "prompt = f\"\"\"Eres profesor de lengua española, corriges errores diciéndolo correctamente indirectamente. mantenga su respuesta breve y simple.\n",
    "\n",
    "User: {input_text}\n",
    "Mini:\"\"\"\n",
    "\n",
    "#%%time\n",
    "\n",
    "sequences = pipeline(\n",
    "    prompt,\n",
    "    #max_length=128,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.7,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(f\"Result: {sequences[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b30336f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: You are a Spanish language teacher, you correct errors by repeat with user said in correct format. Keep your answer short and simple.\n",
      "\n",
      "User: Bien, gracias. ¿Y en ti?\n",
      "Mini: ¡Hola! ¡Muchas gracias! ¿Y en ti?\n",
      "User \n"
     ]
    }
   ],
   "source": [
    "# prompt enginnering\n",
    "prompt = f\"\"\"You are a Spanish language teacher, you correct errors by repeat with user said in correct format. Keep your answer short and simple.\n",
    "\n",
    "User: {input_text}\n",
    "Mini: \"\"\"\n",
    "\n",
    "#%%time\n",
    "\n",
    "sequences = pipeline(\n",
    "    prompt,\n",
    "    #max_length=128,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.7,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(f\"Result: {sequences[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac16766e",
   "metadata": {},
   "source": [
    "## vector datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "338a6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "864456ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install datasets\n",
    "#import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82da4874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_json('forLLM.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6905cbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Me llamo Jess.</td>\n",
       "      <td>Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Te llamo Jess.</td>\n",
       "      <td>Ah, tu nombre es Jess. ¡Encantado de conocerte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llamo Jess.</td>\n",
       "      <td>Ah, eres Jess. ¡Un placer conocerte!  ¿Cómo te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Me llamas Jess.</td>\n",
       "      <td>Ah, te llamas Jess. ¡Es un placer!  ¿Cómo te va?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me soy Jess.</td>\n",
       "      <td>Ah, ¿así que eres Jess? ¡Encantado!  ¿Cómo te va?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          question                                             answer\n",
       "0   Me llamo Jess.    Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?\n",
       "1   Te llamo Jess.  Ah, tu nombre es Jess. ¡Encantado de conocerte...\n",
       "2      Llamo Jess.  Ah, eres Jess. ¡Un placer conocerte!  ¿Cómo te...\n",
       "3  Me llamas Jess.   Ah, te llamas Jess. ¡Es un placer!  ¿Cómo te va?\n",
       "4     Me soy Jess.  Ah, ¿así que eres Jess? ¡Encantado!  ¿Cómo te va?"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "94082068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bien, gracias. ¿Y a ti?</td>\n",
       "      <td>Muy bien. Vivo en la Ciudad de México. ¿De dón...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bien, gracias. ¿Y en ti?</td>\n",
       "      <td>Estoy genial. Soy de la Ciudad de México. ¿De ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bien, gracias. ¿Y ti?</td>\n",
       "      <td>Me encuentro muy bien. Vengo de la Ciudad de M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bien, gracias. ¿Y a tú?</td>\n",
       "      <td>Estoy excelente. Nací en la Ciudad de México. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bien gracias, ¿y a ti?</td>\n",
       "      <td>Todo va de maravilla. Mi ciudad es la Ciudad d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>¿Y a ti? Bien, gracias.</td>\n",
       "      <td>Me siento estupendo. La Ciudad de México es mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    question  \\\n",
       "6    Bien, gracias. ¿Y a ti?   \n",
       "7   Bien, gracias. ¿Y en ti?   \n",
       "8      Bien, gracias. ¿Y ti?   \n",
       "9    Bien, gracias. ¿Y a tú?   \n",
       "10    Bien gracias, ¿y a ti?   \n",
       "11   ¿Y a ti? Bien, gracias.   \n",
       "\n",
       "                                               answer  \n",
       "6   Muy bien. Vivo en la Ciudad de México. ¿De dón...  \n",
       "7   Estoy genial. Soy de la Ciudad de México. ¿De ...  \n",
       "8   Me encuentro muy bien. Vengo de la Ciudad de M...  \n",
       "9   Estoy excelente. Nací en la Ciudad de México. ...  \n",
       "10  Todo va de maravilla. Mi ciudad es la Ciudad d...  \n",
       "11  Me siento estupendo. La Ciudad de México es mi...  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset[6:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59c8bc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "Extracting data files: 100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2486.25it/s]\n",
      "Generating train split: 37 examples [00:00, 6430.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('json', data_files = 'forLLM.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf8b3a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question'],\n",
       "        num_rows: 37\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15c454a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac3455f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9976897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?',\n",
       " 'question': 'Me llamo Jess.'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ec2caec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ad2f957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)5fedf/.gitattributes: 100%|████████████████████████████████████████████████████████████████████| 737/737 [00:00<00:00, 4.88MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|████████████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 1.91MB/s]\n",
      "Downloading (…)2cb455fedf/README.md: 100%|████████████████████████████████████████████████████████████████| 11.5k/11.5k [00:00<00:00, 92.9MB/s]\n",
      "Downloading (…)b455fedf/config.json: 100%|████████████████████████████████████████████████████████████████████| 612/612 [00:00<00:00, 6.94MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 1.36MB/s]\n",
      "Downloading (…)edf/data_config.json: 100%|████████████████████████████████████████████████████████████████| 25.5k/25.5k [00:00<00:00, 3.37MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████████████████████████████████████████████████████████████████| 90.9M/90.9M [00:02<00:00, 44.4MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|███████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 441kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 1.22MB/s]\n",
      "Downloading (…)5fedf/tokenizer.json: 100%|██████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 2.02MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████████████████████████████| 383/383 [00:00<00:00, 3.39MB/s]\n",
      "Downloading (…)fedf/train_script.py: 100%|████████████████████████████████████████████████████████████████| 13.8k/13.8k [00:00<00:00, 72.2MB/s]\n",
      "Downloading (…)2cb455fedf/vocab.txt: 100%|██████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 10.0MB/s]\n",
      "Downloading (…)455fedf/modules.json: 100%|████████████████████████████████████████████████████████████████████| 349/349 [00:00<00:00, 1.57MB/s]\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"langbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc9a3052",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset['train'])):\n",
    "  collection.add(\n",
    "        embeddings=[model.encode(f\"{dataset['train'][i]['question']}. {dataset['train'][i]['answer']}\").tolist()],\n",
    "        documents=[dataset['train'][i]['answer']],\n",
    "        ids=[f\"id_{i}\"]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98ad3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(dataset)):\n",
    "#  collection.add(\n",
    "#        embeddings=[model.encode(f\"{dataset[i]['correct_answer']}. {dataset[i]['support']}\").tolist()],\n",
    "#        documents=[dataset[i]['support']],\n",
    "#        ids=[f\"id_{i}\"]\n",
    "#  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "03a5a994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id_8', 'id_6', 'id_9']], 'distances': [[0.8660387396812439, 0.8931632041931152, 0.9422783851623535]], 'metadatas': [[None, None, None]], 'embeddings': None, 'documents': [['Me encuentro muy bien. Vengo de la Ciudad de México. ¿Y tú, de dónde eres?', 'Muy bien. Vivo en la Ciudad de México. ¿De dónde eres tú?', 'Estoy excelente. Nací en la Ciudad de México. ¿Tú de dónde vienes?']]}\n"
     ]
    }
   ],
   "source": [
    "#user_question = \"Mi llamo Jess.\"\n",
    "user_question = \"no me siento bien\"\n",
    "\n",
    "context = collection.query(\n",
    "  query_embeddings=[model.encode(user_question).tolist()],\n",
    "  n_results=3\n",
    ")\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "73b3b374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Me encuentro muy bien. Vengo de la Ciudad de México. ¿Y tú, de dónde eres?',\n",
       " 'Muy bien. Vivo en la Ciudad de México. ¿De dónde eres tú?',\n",
       " 'Estoy excelente. Nací en la Ciudad de México. ¿Tú de dónde vienes?']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "113ee426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Me encuentro muy bien. Vengo de la Ciudad de México. ¿Y tú, de dónde eres?'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context['documents'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6619887f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Muy bien. Vivo en la Ciudad de México. ¿De dónde eres tú?'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context['documents'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b2ea99d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id_6', 'id_8', 'id_9']], 'distances': [[0.5318814516067505, 0.5845593810081482, 0.6315627098083496]], 'metadatas': [[None, None, None]], 'embeddings': None, 'documents': [['Muy bien. Vivo en la Ciudad de México. ¿De dónde eres tú?', 'Me encuentro muy bien. Vengo de la Ciudad de México. ¿Y tú, de dónde eres?', 'Estoy excelente. Nací en la Ciudad de México. ¿Tú de dónde vienes?']]}\n"
     ]
    }
   ],
   "source": [
    "#user_question = \"Mi llamo Jess.\"\n",
    "user_question = \"bien gracias. ¿Y a ti?\"\n",
    "\n",
    "context = collection.query(\n",
    "  query_embeddings=[model.encode(user_question).tolist()],\n",
    "  n_results=3\n",
    ")\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "36c7d83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id_27', 'id_36', 'id_35']], 'distances': [[1.072309970855713, 1.083794355392456, 1.0871548652648926]], 'metadatas': [[None, None, None]], 'embeddings': None, 'documents': [['Te presento tus dos cafés. Debes 2 pesos. ¿Usarás crédito?', 'Te doy las gracias. ¡Nos vemos pronto!', 'Agradezco mucho. Hasta muy pronto.']]}\n"
     ]
    }
   ],
   "source": [
    "#user_question = \"Mi llamo Jess.\"\n",
    "user_question = \"Te Amo\"\n",
    "\n",
    "context = collection.query(\n",
    "  query_embeddings=[model.encode(user_question).tolist()],\n",
    "  n_results=3\n",
    ")\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a0553",
   "metadata": {},
   "source": [
    "## run with embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "abcccca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"You are a Spanish tutor. You respond in Spanish only.\n",
    "User: {user_question}\n",
    "Mini: {\"\".join(context['documents'][0][0])}.\n",
    "\n",
    "{user_question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9641902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"You are a Spanish tutor. Repeat what user says and make sure you answer based on user's input in Spanish. For example\n",
    "User: Bien, gracias. ¿Y a ti?\n",
    "Assistant: {\"\".join(context['documents'][0][0])}\n",
    "----\n",
    "User: Bien, gracias. ¿Y en ti?\n",
    "Assistant: {\"\".join(context['documents'][0][1])}\n",
    "----\n",
    "User: Bien, gracias. ¿Y ti?\n",
    "Assistant: {\"\".join(context['documents'][0][2])}\n",
    "----\n",
    "User: {user_question}\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6f1b67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Answer by repeating this first.\n",
    "User: {user_question}\n",
    "Mini: {\"\".join(context['documents'][0][0])}\n",
    "----\n",
    "User: {user_question}\n",
    "Mini: {\"\".join(context['documents'][0][1])}\n",
    "----\n",
    "User: {user_question}\n",
    "Mini: {\"\".join(context['documents'][0][2])}\n",
    "----\n",
    "User: {user_question}\n",
    "Mini:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2a6d904f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: You are a Spanish tutor. Repeat what user says and make sure you answer based on user's input in Spanish. For example\n",
      "User: Bien, gracias. ¿Y a ti?\n",
      "Assistant: Me encuentro muy bien. Vengo de la Ciudad de México. ¿Y tú, de dónde eres?\n",
      "----\n",
      "User: Bien, gracias. ¿Y en ti?\n",
      "Assistant: Muy bien. Vivo en la Ciudad de México. ¿De dónde eres tú?\n",
      "----\n",
      "User: Bien, gracias. ¿Y ti?\n",
      "Assistant: Estoy excelente. Nací en la Ciudad de México. ¿Tú de dónde vienes?\n",
      "----\n",
      "User: no me siento bien\n",
      "Assistant:\n",
      "Me siento mal.\n",
      "User \n",
      "CPU times: user 265 ms, sys: 16.1 ms, total: 281 ms\n",
      "Wall time: 282 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sequences = pipeline(\n",
    "    prompt,\n",
    "    #max_length=128,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.7,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(f\"Result: {sequences[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8d60b",
   "metadata": {},
   "source": [
    "## use a different setence transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be0e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_model2 = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "chroma_client2 = chromadb.Client()\n",
    "collection2 = chroma_client2.create_collection(name=\"langbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset['train'])):\n",
    "  collection2.add(\n",
    "        documents=[st_model2.encode(f\"{dataset['train'][i]['question']}. {dataset['train'][i]['answer']}\").tolist()],\n",
    "        documents=[dataset['train'][i]['answer']],\n",
    "        ids=[f\"id_{i}\"]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb62ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_question = \"Mi llamo Jess.\"\n",
    "user_question = \"no me siento bien\"\n",
    "\n",
    "context2 = collection2.query(\n",
    "  query_embeddings=[st_model2.encode(user_question).tolist()],\n",
    "  n_results=3\n",
    ")\n",
    "\n",
    "print(context2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f545e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966aa6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b5c6f95",
   "metadata": {},
   "source": [
    "## use falcon instruct to explain grammar error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e74a0c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_input = 'Te llamo Jess.'\n",
    "sp_target = 'Me llamo Jess.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "90bde3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shots\n",
    "input_text = f\"\"\"Eres un profesor de español, y puedes explicar qué tipo de error gramatical es cuando proporcionas una oración de entrada y una oración correcta. \n",
    "entrada: '{sp_input}'\n",
    "correcta: '{sp_target}'\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a4bab0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Eres un profesor de español, y puedes explicar qué tipo de error gramatical es cuando proporcionas una oración de entrada y una oración correcta. \n",
      "entrada: 'Te llamo Jess.'\n",
      "correcta: 'Me llamo Jess.'\n",
      "\n",
      "\n",
      "\n",
      "In the sentence 'Te llamo Jess,' the error is in the word 'Te.' It should be 'Me llamo Jess.' The correct sentence is 'Me llamo Jess.' The error is in the word 'entrada,' which should be 'entrada' instead of \n",
      "CPU times: user 1.65 s, sys: 0 ns, total: 1.65 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sequences = pipeline(\n",
    "    input_text,\n",
    "    #max_length=128,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.7,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(f\"Result: {sequences[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f9522ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shots\n",
    "input_text = f\"\"\"You are a Spanish teacher, and you can explain what type of grammatical error it is when providing an input sentence and a correct sentence. \n",
    "Input: '{sp_input}'\n",
    "Correct: '{sp_target}'\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f5802eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: You are a Spanish teacher, and you can explain what type of grammatical error it is when providing an input sentence and a correct sentence. \n",
      "Input: 'Te llamo Jess.'\n",
      "Correct: 'Me llamo Jess.'\n",
      "\n",
      "\n",
      "\n",
      "In the input sentence, there is a grammatical error because the subject 'Te llamo' is not in the correct form 'Me llamo'. The correct form should be 'Me llamo Jess'. The error is a subject-verb agreement error.\n",
      "CPU times: user 1.42 s, sys: 0 ns, total: 1.42 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sequences = pipeline(\n",
    "    input_text,\n",
    "    #max_length=128,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.7,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(f\"Result: {sequences[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "09882088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shots\n",
    "input_text = f\"\"\"You are a Spanish teacher, and you speak Spanish only and you are explaining what type of grammatical error it is when providing an input sentence and a correct sentence. \n",
    "Input: '{sp_input}'\n",
    "Correct: '{sp_target}'\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5b195c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: You are a Spanish teacher, and you speak Spanish only and you are explaining what type of grammatical error it is when providing an input sentence and a correct sentence. \n",
      "Input: 'Te llamo Jess.'\n",
      "Correct: 'Me llamo Jess.'\n",
      "\n",
      "\n",
      "\n",
      "In Spanish, the verb 'te llamo' should be used with the subject pronoun'me' to form a complete sentence. The correct sentence is 'Me llamo Jess.'\n",
      "CPU times: user 1.07 s, sys: 798 µs, total: 1.07 s\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sequences = pipeline(\n",
    "    input_text,\n",
    "    #max_length=128,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.7,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(f\"Result: {sequences[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e47fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06beeb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "query = \"How many people live in London?\"\n",
    "docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "\n",
    "#Load the model\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "#Encode query and documents\n",
    "query_emb = model.encode(query)\n",
    "doc_emb = model.encode(docs)\n",
    "\n",
    "#Compute dot score between query and all document embeddings\n",
    "scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "#Combine docs & scores\n",
    "doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "#Sort by decreasing score\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#Output passages & scores\n",
    "for doc, score in doc_score_pairs:\n",
    "    print(score, doc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
