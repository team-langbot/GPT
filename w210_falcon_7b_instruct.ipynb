{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cb97013",
   "metadata": {},
   "source": [
    "## falcon 7B instruct talk in Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b6819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c1f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "#model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "model = \"falcon_7b_instruct\"\n",
    "\n",
    "access_token = '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'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    token=access_token,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d151c2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Mini:Hello, how are you?\n",
      "User:Good, and you?\n",
      "Mini:I'm doing well, thank you. Do you have any plans for the weekend?\n",
      "User: Actually, I'm thinking of going to the beach.\n",
      "Mini: That sounds relaxing. Have you packed your sunscreen and a towel?\n",
      "User: Yes, I have. Are you thinking of going to the beach this weekend as well?\n",
      "Mini: Well, it depends. I need to finish a few projects first. What about you?\n",
      "User: I think I might try to find a new restaurant to check out.\n",
      "Mini: That sounds like a good idea. Have you had any new restaurant recommendations lately?\n",
      "User: Yes, actually. I heard a new place called \"The Grilled Cheese Kitchen\" has really good sandwiches. Have you tried their sandwiches?\n",
      "Mini: I haven't yet, but they do look delicious. I might have to check it out.\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "   \"Mini:Hello, how are you?\\nUser:\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c95d299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: User:hola, cómo estás?\n",
      "Mini: Hola, gracias. ¿\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "   \"User:hola, cómo estás?\\nMini:\",\n",
    "    #max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40f78736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shots\n",
    "input_text = \"\"\"\n",
    "Oració: Estoy bien, gracias.\n",
    "Paráfrasis: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
    "----\n",
    "Oració: no me sirve.\n",
    "Paráfrasis: Tú no estás bien, yo estoy bien. ¿Dónde vive?\n",
    "----\n",
    "Oración: Estoy bien.\n",
    "Paráfrasis: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
    "----\n",
    "Oració: Estoy muy bien.\n",
    "Paráfrasis:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f758d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shots\n",
    "input_text = \"\"\"\n",
    "User: Estoy bien, gracias.\n",
    "Mini: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
    "----\n",
    "User: no me sirve.\n",
    "Mini: Tú no estás bien, yo estoy bien. ¿Dónde vive?\n",
    "----\n",
    "User: Estoy muy bien.\n",
    "Mini:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "268e9ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "User: Estoy bien, gracias.\n",
      "Mini: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
      "----\n",
      "User: no me sirve.\n",
      "Mini: Tú no estás bien, yo estoy bien. ¿Dónde vive?\n",
      "----\n",
      "User: Estoy muy bien.\n",
      "Mini: Tú no estás bien, yo tengo mala espina. ¿Dónde vivo?\n",
      "User: Estoy perfecto, no tengo dolencia. ¿Dónde vivo?\n",
      "Mini: Yo tengo una dolencia, tú no tengo\n",
      "CPU times: user 1.33 s, sys: 698 µs, total: 1.33 s\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequences = pipeline(\n",
    "    input_text,\n",
    "    max_length=128,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51787a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "<human>: Estoy bien, gracias.\n",
    "<assistant>: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
    "----\n",
    "<human>: no me sirve.\n",
    "<assistant>: Tú no estás bien, yo estoy bien. ¿Dónde vive?\n",
    "----\n",
    "<human>: Estoy muy bien.\n",
    "<assistant>:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39083789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: <human>: Estoy bien, gracias.\n",
      "<assistant>: Tú estás bien, yo también estoy bien. ¿Dónde vive?\n",
      "----\n",
      "<human>: no me sirve.\n",
      "<assistant>: Tú no estás bien, yo estoy bien. ¿Dónde vive?\n",
      "----\n",
      "<human>: Estoy muy bien.\n",
      "<assistant>: Tú no estás bien, yo estoy bien. ¿Dónde vivo?\n",
      "----\n",
      "<human>: Estoy bien.\n",
      "<assistant>: Tú no estás bien, yo estoy bien. ¿Dónde vivo?\n",
      "----\n",
      "<human>: Estoy bien.\n",
      "<ass\n",
      "CPU times: user 1.63 s, sys: 27.3 ms, total: 1.65 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sequences = pipeline(\n",
    "    input_text,\n",
    "    #max_length=128,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.7,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(f\"Result: {sequences[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.save_pretrained(\"falcon_7b_instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0bc78",
   "metadata": {},
   "source": [
    "## vector datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a374e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d66c5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install datasets\n",
    "#import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f252919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_json('forLLM.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6fd3eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Me llamo Jess.</td>\n",
       "      <td>Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Te llamo Jess.</td>\n",
       "      <td>Ah, tu nombre es Jess. ¡Encantado de conocerte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llamo Jess.</td>\n",
       "      <td>Ah, eres Jess. ¡Un placer conocerte!  ¿Cómo te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Me llamas Jess.</td>\n",
       "      <td>Ah, te llamas Jess. ¡Es un placer!  ¿Cómo te va?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me soy Jess.</td>\n",
       "      <td>Ah, ¿así que eres Jess? ¡Encantado!  ¿Cómo te va?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          question                                             answer\n",
       "0   Me llamo Jess.    Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?\n",
       "1   Te llamo Jess.  Ah, tu nombre es Jess. ¡Encantado de conocerte...\n",
       "2      Llamo Jess.  Ah, eres Jess. ¡Un placer conocerte!  ¿Cómo te...\n",
       "3  Me llamas Jess.   Ah, te llamas Jess. ¡Es un placer!  ¿Cómo te va?\n",
       "4     Me soy Jess.  Ah, ¿así que eres Jess? ¡Encantado!  ¿Cómo te va?"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503b376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d11c0bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "Extracting data files: 100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2486.25it/s]\n",
      "Generating train split: 37 examples [00:00, 6430.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('json', data_files = 'forLLM.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "660cd870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question'],\n",
       "        num_rows: 37\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a89e0086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96662d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99051dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?',\n",
       " 'question': 'Me llamo Jess.'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6def68d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0be4ac4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)5fedf/.gitattributes: 100%|████████████████████████████████████████████████████████████████████| 737/737 [00:00<00:00, 4.88MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|████████████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 1.91MB/s]\n",
      "Downloading (…)2cb455fedf/README.md: 100%|████████████████████████████████████████████████████████████████| 11.5k/11.5k [00:00<00:00, 92.9MB/s]\n",
      "Downloading (…)b455fedf/config.json: 100%|████████████████████████████████████████████████████████████████████| 612/612 [00:00<00:00, 6.94MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 1.36MB/s]\n",
      "Downloading (…)edf/data_config.json: 100%|████████████████████████████████████████████████████████████████| 25.5k/25.5k [00:00<00:00, 3.37MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████████████████████████████████████████████████████████████████| 90.9M/90.9M [00:02<00:00, 44.4MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|███████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 441kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 1.22MB/s]\n",
      "Downloading (…)5fedf/tokenizer.json: 100%|██████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 2.02MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████████████████████████████| 383/383 [00:00<00:00, 3.39MB/s]\n",
      "Downloading (…)fedf/train_script.py: 100%|████████████████████████████████████████████████████████████████| 13.8k/13.8k [00:00<00:00, 72.2MB/s]\n",
      "Downloading (…)2cb455fedf/vocab.txt: 100%|██████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 10.0MB/s]\n",
      "Downloading (…)455fedf/modules.json: 100%|████████████████████████████████████████████████████████████████████| 349/349 [00:00<00:00, 1.57MB/s]\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"langbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8120fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset['train'])):\n",
    "  collection.add(\n",
    "        embeddings=[model.encode(f\"{dataset['train'][i]['question']}. {dataset['train'][i]['answer']}\").tolist()],\n",
    "        documents=[dataset['train'][i]['answer']],\n",
    "        ids=[f\"id_{i}\"]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fab4ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(dataset)):\n",
    "#  collection.add(\n",
    "#        embeddings=[model.encode(f\"{dataset[i]['correct_answer']}. {dataset[i]['support']}\").tolist()],\n",
    "#        documents=[dataset[i]['support']],\n",
    "#        ids=[f\"id_{i}\"]\n",
    "#  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "838612fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id_0', 'id_5', 'id_3']], 'distances': [[0.8802882432937622, 0.9656923413276672, 1.0032299757003784]], 'metadatas': [[None, None, None]], 'embeddings': None, 'documents': [['Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?', 'Ah, te llamas Mike. ¡Mucho gusto! ¿Cómo te va?', 'Ah, te llamas Jess. ¡Es un placer!  ¿Cómo te va?']]}\n"
     ]
    }
   ],
   "source": [
    "#user_question = \"Mi llamo Jess.\"\n",
    "user_question = \"Te llamo Isabel.\"\n",
    "\n",
    "context = collection.query(\n",
    "  query_embeddings=[model.encode(user_question).tolist()],\n",
    "  n_results=3\n",
    ")\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bdf86062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?',\n",
       " 'Ah, te llamas Mike. ¡Mucho gusto! ¿Cómo te va?',\n",
       " 'Ah, te llamas Jess. ¡Es un placer!  ¿Cómo te va?']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7d092c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context['documents'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "94ba7872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, te llamas Mike. ¡Mucho gusto! ¿Cómo te va?'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context['documents'][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cef1d1",
   "metadata": {},
   "source": [
    "## run with embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "89732889",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Answer the question as truthfully as possible using the provided text, and if the answer is not contained within the text below, say 'I don't know'.\n",
    "Text: {\"\".join(context['documents'][0])}.\n",
    "\n",
    "{user_question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "abca324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"You are a Spanish tutor, respond correctly in Spanish.\n",
    "User: {user_question}\n",
    "Mini: {\"\".join(context['documents'][0][0])}\n",
    "----\n",
    "User: {user_question}\n",
    "Mini: {\"\".join(context['documents'][0][1])}\n",
    "----\n",
    "User: {user_question}\n",
    "Mini: {\"\".join(context['documents'][0][2])}\n",
    "----\n",
    "User: {user_question}\n",
    "Mini:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "71083a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: You are a Spanish tutor, respond correctly in Spanish.\n",
      "User: Te llamo Isabel.\n",
      "Mini: Ah, te llamas Jess. ¡Mucho gusto!  ¿Cómo te va?\n",
      "----\n",
      "User: Te llamo Isabel.\n",
      "Mini: Ah, te llamas Mike. ¡Mucho gusto! ¿Cómo te va?\n",
      "----\n",
      "User: Te llamo Isabel.\n",
      "Mini: Ah, te llamas Jess. ¡Es un placer!  ¿Cómo te va?\n",
      "----\n",
      "User: Te llamo Isabel.\n",
      "Mini:\n",
      "Ah, te llamas Jess. ¡Es un placer! ¿Cómo te va?\n",
      "User \n",
      "CPU times: user 650 ms, sys: 0 ns, total: 650 ms\n",
      "Wall time: 648 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sequences = pipeline(\n",
    "    prompt,\n",
    "    #max_length=128,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.7,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(f\"Result: {sequences[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81268037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "query = \"How many people live in London?\"\n",
    "docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "\n",
    "#Load the model\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "#Encode query and documents\n",
    "query_emb = model.encode(query)\n",
    "doc_emb = model.encode(docs)\n",
    "\n",
    "#Compute dot score between query and all document embeddings\n",
    "scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "#Combine docs & scores\n",
    "doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "#Sort by decreasing score\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#Output passages & scores\n",
    "for doc, score in doc_score_pairs:\n",
    "    print(score, doc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
