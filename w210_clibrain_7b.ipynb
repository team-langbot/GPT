{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3704672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU transformers bitsandbytes einops trl accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c080d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b82f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y transformer-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267914d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abffd7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c759f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#access_token = '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'\n",
    "#model_id = \"clibrain/Llama-2-7b-ft-instruct-es\"\n",
    "model_id = \"llama2_7b_instruct_es\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8072a6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-10:\n",
      "Process ForkProcess-29:\n",
      "Process ForkProcess-32:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-26:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-23:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-27:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-24:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-25:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-30:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-22:\n",
      "Process ForkProcess-28:\n",
      "Process ForkProcess-31:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    #token=access_token,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.save_pretrained(\"llama2_7b_instruct_es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be545d6",
   "metadata": {},
   "source": [
    "A continuación se muestra una instrucción con errores gramaticales que describe una tarea. Escriba una respuesta que complete adecuadamente la solicitud en una oración.\n",
    "\n",
    "### Instrucción:\n",
    "Bien, gracias. ¿Y te ti?\n",
    "\n",
    "### Respuesta:\n",
    "\n",
    "A continuación se muestra una instrucción con errores gramaticales que describe una tarea. Escriba una respuesta que corrija el error y complete adecuadamente la solicitud en una oración. No continúes la conversación.\n",
    "\n",
    "A continuación se muestra una instrucción con errores gramaticales que describe una tarea. Escriba una respuesta que comience con \"Entiendo\" y luego corrija el error. Al finalizar, completa adecuadamente la solicitud y luego detiene la conversación.\n",
    "\n",
    "Siempre dices \"Veo. Tú estás diciendo\" y luego repites lo que digo pero en un formato gramatical correcto. Haz una pausa y, si se te hace una pregunta, respóndela de manera corta y directa sin hacer otra pregunta. Si no se ha hecho ninguna pregunta, finaliza la conversación sin hacer otra pregunta.\n",
    "\n",
    "No me siento bien. ¿y tú?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb461183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_text = 'No mi siento bien. ¿y tú?'\n",
    "#input_text = 'Bien, gracias. ¿Y te ti?'\n",
    "input_text = 'un cafes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8fb239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instrucción:\n",
      "un cafes\n",
      "\n",
      "### Respuesta:\n",
      "Un café.\n",
      "\n",
      "### Instrucción:\n",
      "un café\n",
      "\n",
      "### Respuesta:\n",
      "Un café.\n",
      "\n",
      "### Instrucción:\n",
      "un café\n",
      "\n",
      "### Respuesta:\n",
      "Un café.\n",
      "\n",
      "### Instrucción:\n",
      "un café\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "### Instrucción:\n",
    "{input_text}\n",
    "\n",
    "### Respuesta:\n",
    "\"\"\"\n",
    "\n",
    "result = pipeline(\n",
    "    prompt,\n",
    "    #max_length=128,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature = 0.1,\n",
    "    top_p=0.75,\n",
    "    top_k=50,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f0c5d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A continuación se muestra una instrucción con errores gramaticales que describe una tarea. Escriba una respuesta que comience con \"Si,\" con la corrección de la frase de instrucción. Cuando termine, complete correctamente la solicitud y luego detenga la conversación.\n",
      "### Instrucción:\n",
      "No mi siento bien. ¿y tú?\n",
      "\n",
      "### Respuesta:\n",
      "Si no me siento bien, ¿y tú? Estoy bien. ¿Y tú? Estoy bien. ¿Y tú? Estoy bien. ¿Y tú? Estoy bien. ¿Y tú? Estoy bien. ¿Y tú? Estoy bien. ¿Y t\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "A continuación se muestra una instrucción con errores gramaticales que describe una tarea. Escriba una respuesta que comience con \"Si,\" con la corrección de la frase de instrucción. Cuando termine, complete correctamente la solicitud y luego detenga la conversación.\n",
    "### Instrucción:\n",
    "No mi siento bien. ¿y tú?\n",
    "\n",
    "### Respuesta:\n",
    "\"\"\"\n",
    "\n",
    "result = pipeline(\n",
    "    prompt,\n",
    "    #max_length=128,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature = 0.1,\n",
    "    top_p=0.75,\n",
    "    top_k=50,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101215d",
   "metadata": {},
   "source": [
    "        \"Instrucción\": instruction,\n",
    "        \"Entrada\": input_data,\n",
    "        \"Contexto\": context,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9e6524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aquí tienes una instrucción con errores gramaticales que describe una tarea. Repite la instrucción en un formato gramatical correcto. Completa adecuadamente la solicitud.\n",
      "### Instrucción:\n",
      "No mi siento bien. ¿y tú?\n",
      "\n",
      "### Respuesta:\n",
      "No me siento bien. ¿Y tú?\n",
      "\n",
      "### Instrucción:\n",
      "¿Cómo se siente?\n",
      "\n",
      "### Respuesta:\n",
      "No me siento bien. ¿Y tú?\n",
      "\n",
      "### Instrucción:\n",
      "¿Cómo se siente?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Aquí tienes una instrucción con errores gramaticales que describe una tarea. Repite la instrucción en un formato gramatical correcto. Completa adecuadamente la solicitud.\n",
    "### Instrucción:\n",
    "No mi siento bien. ¿y tú?\n",
    "\n",
    "### Respuesta:\n",
    "\"\"\"\n",
    "\n",
    "result = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature = 0.1,\n",
    "    top_p=0.75,\n",
    "    top_k=50,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0f9066b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aquí tienes una instrucción con errores gramaticales que describe una tarea. Repite la instrucción en un formato gramatical correcto. Completa adecuadamente la solicitud.\n",
      "### Instrucción:\n",
      "Bien, gracias. ¿Y a ti?\n",
      "\n",
      "### Respuesta:\n",
      "Ya veo, te refieres a Bien, gracias. ¿Y a ti? Muy bien.\n",
      "\n",
      "### Instrucción:\n",
      "Bien, gracias. ¿Y en ti?\n",
      "\n",
      "### Respuesta:\n",
      "Ya veo, te refieres a Bien, gracias. ¿Y a ti? Estoy genial.\n",
      "\n",
      "### Instrucción:\n",
      "Bien, gracias. ¿Y ti?\n",
      "\n",
      "### Respuesta:\n",
      "Ya veo, te refieres a Bien, gracias. ¿Y a ti? Me encuentro muy bien.\n",
      "\n",
      "### Instrucción:\n",
      "No mi siento bien. ¿y tú?\n",
      "\n",
      "### Respuesta:\n",
      "No, no me siento bien. ¿Y tú? No, no me siento bien.\n",
      "\n",
      "### Instrucción:\n",
      "No, no me siento bien. ¿Y tú? No, no me siento bien.\n",
      "\n",
      "### Respuesta:\n",
      "No, no me s\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Aquí tienes una instrucción con errores gramaticales que describe una tarea. Repite la instrucción en un formato gramatical correcto. Completa adecuadamente la solicitud.\n",
    "### Instrucción:\n",
    "Bien, gracias. ¿Y a ti?\n",
    "\n",
    "### Respuesta:\n",
    "Ya veo, te refieres a Bien, gracias. ¿Y a ti? Muy bien.\n",
    "\n",
    "### Instrucción:\n",
    "Bien, gracias. ¿Y en ti?\n",
    "\n",
    "### Respuesta:\n",
    "Ya veo, te refieres a Bien, gracias. ¿Y a ti? Estoy genial.\n",
    "\n",
    "### Instrucción:\n",
    "Bien, gracias. ¿Y ti?\n",
    "\n",
    "### Respuesta:\n",
    "Ya veo, te refieres a Bien, gracias. ¿Y a ti? Me encuentro muy bien.\n",
    "\n",
    "### Instrucción:\n",
    "No mi siento bien. ¿y tú?\n",
    "\n",
    "### Respuesta:\n",
    "\"\"\"\n",
    "\n",
    "result = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    temperature = 0.1,\n",
    "    top_p=0.75,\n",
    "    top_k=50,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363e1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0655aac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca1a026b",
   "metadata": {},
   "source": [
    "### Test RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8230812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c50ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb0f9a61",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932080c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Dame una lista de lugares a visitar en España.\"\n",
    "print(generate(instruction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a131c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eba0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200, device=0)\n",
    ")\n",
    "\n",
    "prompt = \"\"\"\n",
    "A continuación hay una instrucción que describe una tarea. Escriba una respuesta que complete adecuadamente la solicitud.\n",
    "### Instrucción:\n",
    "Dame una lista de 5 lugares a visitar en España.\n",
    "\n",
    "### Respuesta:\n",
    "\"\"\"\n",
    "\n",
    "result = pipe(prompt)\n",
    "print(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ecd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pipeline(\n",
    "   \"Mini:Hello, how are you?\\nUser:\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8680f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2093bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sequences = pipeline(\n",
    "    input_text,\n",
    "    max_length=128,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825c2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7892dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using pipeline\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline \n",
    "\n",
    "model_id = \"clibrain/Llama-2-7b-ft-instruct-es\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200, device=0)\n",
    "\n",
    "prompt = \"\"\"\n",
    "A continuación hay una instrucción que describe una tarea. Escriba una respuesta que complete adecuadamente la solicitud.\n",
    "### Instrucción:\n",
    "Dame una lista de 5 lugares a visitar en España.\n",
    "\n",
    "### Respuesta:\n",
    "\"\"\"\n",
    "\n",
    "result = pipe(prompt)\n",
    "print(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fedfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    token=access_token,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e6bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35853f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline \n",
    "\n",
    "model_id = \"clibrain/Llama-2-7b-ft-instruct-es\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200, device=0)\n",
    "\n",
    "prompt = \"\"\"\n",
    "A continuación hay una instrucción que describe una tarea. Escriba una respuesta que complete adecuadamente la solicitud.\n",
    "### Instrucción:\n",
    "Dame una lista de 5 lugares a visitar en España.\n",
    "\n",
    "### Respuesta:\n",
    "\"\"\"\n",
    "\n",
    "result = pipe(prompt)\n",
    "print(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f5698f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "model_id = \"clibrain/Llama-2-7b-ft-instruct-es\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "def create_instruction(instruction, input_data=None, context=None):\n",
    "    sections = {\n",
    "        \"Instrucción\": instruction,\n",
    "        \"Entrada\": input_data,\n",
    "        \"Contexto\": context,\n",
    "    }\n",
    "\n",
    "    system_prompt = \"A continuación hay una instrucción que describe una tarea, junto con una entrada que proporciona más contexto. Escriba una respuesta que complete adecuadamente la solicitud.\\n\\n\"\n",
    "    prompt = system_prompt\n",
    "\n",
    "    for title, content in sections.items():\n",
    "        if content is not None:\n",
    "            prompt += f\"### {title}:\\n{content}\\n\\n\"\n",
    "\n",
    "    prompt += \"### Respuesta:\\n\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate(\n",
    "        instruction,\n",
    "        input=None,\n",
    "        context=None,\n",
    "        max_new_tokens=128,\n",
    "        temperature=0.1,\n",
    "        top_p=0.75,\n",
    "        top_k=40,\n",
    "        num_beams=4,\n",
    "        **kwargs\n",
    "):\n",
    "    \n",
    "    prompt = create_instruction(instruction, input, context)\n",
    "    print(prompt.replace(\"### Respuesta:\\n\", \"\"))\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(\"cuda\")\n",
    "    attention_mask = inputs[\"attention_mask\"].to(\"cuda\")\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        num_beams=num_beams,\n",
    "        **kwargs,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    s = generation_output.sequences[0]\n",
    "    output = tokenizer.decode(s)\n",
    "    return output.split(\"### Respuesta:\")[1].lstrip(\"\\n\")\n",
    "\n",
    "instruction = \"Dame una lista de lugares a visitar en España.\"\n",
    "print(generate(instruction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f24420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
